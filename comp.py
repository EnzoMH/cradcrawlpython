#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì§„ë³´ëœ ë°ì´í„° ê²€ì¦ ë° í¬ë¡¤ë§ ì‹œìŠ¤í…œ (comp.py)
SystemAnalyzer ê¸°ë°˜ ë™ì  ì›Œì»¤ ê´€ë¦¬, UA ë¡œí…Œì´ì…˜, ì‹¤ì‹œê°„ í—¤ë“œë¦¬ìŠ¤ í† ê¸€ ì§€ì›

ì²˜ë¦¬ ëŒ€ìƒ: rawdatafile/failed_data_250809.csv (3,557í–‰)
ì¶œë ¥: G/H/J/K ì»¬ëŸ¼ + Nì—´ë¶€í„° ê²€ì¦ê°’/ë§í¬/AIì‘ë‹µ
"""

import os, sys, json, time, logging, traceback, threading
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
import socket
# import keyboard  # ì‹¤ì‹œê°„ í—¤ë“œë¦¬ìŠ¤ í† ê¸€ìš© (ì„ íƒì )

from dotenv import load_dotenv

# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° import
from utils.valid.phone_validator import PhoneValidator
from utils.system.web_driver_manager import WebDriverManager
from utils.system.system_analyzer import SystemAnalyzer
from utils.valid.verification_engine import VerificationEngine
from utils.crawler.google_search_engine import GoogleSearchEngine
from utils.crawler.homepage_crawler import HomepageCrawler
from utils.crawler.prt.user_agent_rotator import UserAgentRotator
from utils.ai_model_manager import AIModelManager
from utils.data.data_processor import DataProcessor
from utils.data.excel_processor import ExcelProcessor

# ì„¤ì • import
from config.performance_profiles import PerformanceManager
from config.crawling_settings import CrawlingSettings
from config.settings import get_optimal_config, CRAWLING_PARAMS


class AdvancedPortManager:
    """Valid3.py ë°©ì‹: ê³ ê¸‰ í¬íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ (4ê°œ í¬íŠ¸ë§Œ ì—„ê²© ê´€ë¦¬)"""
    
    def __init__(self, logger):
        """AdvancedPortManager ì´ˆê¸°í™” (4ê°œ í¬íŠ¸ ì „ìš©)"""
        self.logger = logger
        
        # í¬íŠ¸ ë²”ìœ„ ì„¤ì • (4ê°œë§Œ ì—„ê²©íˆ ê´€ë¦¬)
        self.port_range_start = 9222
        self.port_range_end = 9226  # 9222-9225 (4ê°œë§Œ)
        self.available_ports = set(range(self.port_range_start, self.port_range_end))
        self.used_ports = set()
        self.blacklisted_ports = set()  # ì°¨ë‹¨ëœ í¬íŠ¸ë“¤
        self.port_assignments = {}  # ì›Œì»¤ë³„ í¬íŠ¸ í• ë‹¹ ê¸°ë¡
        
        # í¬íŠ¸ ì‚¬ìš© í†µê³„
        self.allocation_count = 0
        self.release_count = 0
        
        self.logger.info(f"ğŸ”Œ AdvancedPortManager ì´ˆê¸°í™”: {len(self.available_ports)}ê°œ í¬íŠ¸ ê´€ë¦¬ ({self.port_range_start}-{self.port_range_end-1})")
    
    def allocate_port(self, worker_id: int) -> int:
        """ì›Œì»¤ì—ê²Œ í¬íŠ¸ í• ë‹¹ (4ê°œ ì œí•œ)"""
        try:
            # ì›Œì»¤ IDë¥¼ 0~3ìœ¼ë¡œ ì œí•œ
            limited_worker_id = worker_id % 4
            
            # ì´ë¯¸ í• ë‹¹ëœ í¬íŠ¸ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
            if limited_worker_id in self.port_assignments:
                existing_port = self.port_assignments[limited_worker_id]
                if existing_port not in self.blacklisted_ports and self._is_port_available(existing_port):
                    self.logger.debug(f"ğŸ”Œ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}): ê¸°ì¡´ í¬íŠ¸ {existing_port} ì¬ì‚¬ìš©")
                    return existing_port
                else:
                    # ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆê±°ë‚˜ ì‚¬ìš© ë¶ˆê°€í•˜ë©´ í•´ì œí•˜ê³  ìƒˆë¡œ í• ë‹¹
                    self.logger.warning(f"âš ï¸ ì›Œì»¤ {limited_worker_id}: ê¸°ì¡´ í¬íŠ¸ {existing_port} ë¬¸ì œë¨, ìƒˆ í¬íŠ¸ í• ë‹¹")
                    self.release_port(existing_port, limited_worker_id)
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ì°¾ê¸°
            available_ports = self.available_ports - self.used_ports - self.blacklisted_ports
            
            if not available_ports:
                # ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ ì˜¤ë˜ëœ í¬íŠ¸ í•´ì œ
                if self.used_ports:
                    oldest_port = min(self.used_ports)
                    self.logger.warning(f"âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ì—†ìŒ, ê°•ì œ í•´ì œ: {oldest_port}")
                    self.release_port(oldest_port)
                    available_ports = self.available_ports - self.used_ports - self.blacklisted_ports
                
                if not available_ports:
                    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¼ë¶€ í•´ì œ
                    if self.blacklisted_ports:
                        released_port = self.blacklisted_ports.pop()
                        self.logger.warning(f"âš ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í¬íŠ¸ í•´ì œ: {released_port}")
                        available_ports = {released_port}
                    else:
                        # ìµœí›„ì˜ ìˆ˜ë‹¨: ê¸°ë³¸ í¬íŠ¸ ì‚¬ìš©
                        emergency_port = self.port_range_start + limited_worker_id
                        self.logger.error(f"ğŸš¨ ê¸´ê¸‰ í¬íŠ¸ í• ë‹¹: {emergency_port}")
                        return emergency_port
            
            # í¬íŠ¸ í• ë‹¹
            allocated_port = min(available_ports)  # ê°€ì¥ ì‘ì€ ë²ˆí˜¸ë¶€í„° ì‚¬ìš©
            self.used_ports.add(allocated_port)
            self.port_assignments[limited_worker_id] = allocated_port
            self.allocation_count += 1
            
            self.logger.debug(f"ğŸ”Œ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}): í¬íŠ¸ {allocated_port} ìƒˆë¡œ í• ë‹¹ (ì´ ì‚¬ìš©ì¤‘: {len(self.used_ports)}/4)")
            return allocated_port
            
        except Exception as e:
            self.logger.error(f"âŒ í¬íŠ¸ í• ë‹¹ ì‹¤íŒ¨ (ì›Œì»¤ {worker_id}): {e}")
            # ê¸´ê¸‰ í¬íŠ¸ ë°˜í™˜
            emergency_port = self.port_range_start + (worker_id % 4)
            self.logger.warning(f"ğŸš¨ ê¸´ê¸‰ í¬íŠ¸ í• ë‹¹: {emergency_port}")
            return emergency_port
    
    def release_port(self, port: int, worker_id: int = None):
        """í¬íŠ¸ ì¦‰ì‹œ í•´ì œ"""
        try:
            if port in self.used_ports:
                self.used_ports.remove(port)
                self.release_count += 1
                
                # ì›Œì»¤ í• ë‹¹ ê¸°ë¡ì—ì„œ ì œê±°
                if worker_id is not None and worker_id in self.port_assignments:
                    if self.port_assignments[worker_id] == port:
                        del self.port_assignments[worker_id]
                else:
                    # worker_idê°€ ì—†ìœ¼ë©´ ì „ì²´ í• ë‹¹ ê¸°ë¡ì—ì„œ ì°¾ì•„ì„œ ì œê±°
                    for wid, assigned_port in list(self.port_assignments.items()):
                        if assigned_port == port:
                            del self.port_assignments[wid]
                            break
                
                self.logger.debug(f"ğŸ”“ í¬íŠ¸ {port} ì¦‰ì‹œ í•´ì œ ì™„ë£Œ (ë‚¨ì€ ì‚¬ìš©ì¤‘: {len(self.used_ports)}/4)")
            else:
                self.logger.debug(f"âš ï¸ í¬íŠ¸ {port} ì´ë¯¸ í•´ì œë¨")
                
        except Exception as e:
            self.logger.error(f"âŒ í¬íŠ¸ í•´ì œ ì‹¤íŒ¨ ({port}): {e}")
    
    def blacklist_port(self, port: int, reason: str = "ì°¨ë‹¨ë¨"):
        """í¬íŠ¸ë¥¼ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"""
        try:
            self.blacklisted_ports.add(port)
            if port in self.used_ports:
                self.used_ports.remove(port)
            
            self.logger.warning(f"ğŸš« í¬íŠ¸ {port} ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¶”ê°€: {reason}")
            
        except Exception as e:
            self.logger.error(f"âŒ í¬íŠ¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì‹¤íŒ¨ ({port}): {e}")
    
    def _is_port_available(self, port: int) -> bool:
        """í¬íŠ¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.settimeout(1)
                result = s.connect_ex(('localhost', port))
                return result != 0  # í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì´ ì•„ë‹˜
        except:
            return False
    
    def release_all_ports(self):
        """ëª¨ë“  í¬íŠ¸ í•´ì œ"""
        try:
            released_count = len(self.used_ports)
            self.used_ports.clear()
            self.port_assignments.clear()
            self.logger.info(f"ğŸ”“ ëª¨ë“  í¬íŠ¸ í•´ì œ ì™„ë£Œ: {released_count}ê°œ")
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë“  í¬íŠ¸ í•´ì œ ì‹¤íŒ¨: {e}")
    
    def get_port_status(self) -> Dict:
        """í¬íŠ¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'total_ports': len(self.available_ports),
            'used_ports': len(self.used_ports),
            'available_ports': len(self.available_ports) - len(self.used_ports) - len(self.blacklisted_ports),
            'blacklisted_ports': len(self.blacklisted_ports),
            'port_assignments': dict(self.port_assignments),
            'allocation_count': self.allocation_count,
            'release_count': self.release_count
        }


@dataclass
class CompValidationResult:
    """comp.pyìš© ê²€ì¦ ê²°ê³¼ êµ¬ì¡°ì²´"""
    row_index: int
    
    # ì›ë³¸ ë°ì´í„°
    region: str  # ì‹œë„
    district: str  # ì‹œêµ°êµ¬  
    institution_name: str  # ìë©´ë™ (ê¸°ê´€ëª…)
    address: str  # ì£¼ì†Œ
    phone: str  # ì „í™”ë²ˆí˜¸
    fax: str  # íŒ©ìŠ¤ë²ˆí˜¸
    
    # G/H/J/K ì»¬ëŸ¼ ê²°ê³¼
    phone_real_institution: str = ""  # G: ì „í™”ë²ˆí˜¸ì˜ ì‹¤ì œê¸°ê´€
    phone_verified: str = ""  # H: ì˜¬ë°”ë¥¸ ì „í™”ë²ˆí˜¸
    fax_real_institution: str = ""  # J: íŒ©ìŠ¤ë²ˆí˜¸ì˜ ì‹¤ì œê¸°ê´€  
    fax_verified: str = ""  # K: ì˜¬ë°”ë¥¸ íŒ©ìŠ¤ë²ˆí˜¸
    
    # N~S ì»¬ëŸ¼: 1~6ì°¨ ê²€ì¦ê°’
    validation_1st: str = ""  # N: 1ì°¨ê²€ì¦ê°’ (ì§€ì—­ë²ˆí˜¸ ë§¤ì¹­)
    validation_2nd: str = ""  # O: 2ì°¨ê²€ì¦ê°’ (êµ¬ê¸€ ê²€ìƒ‰)
    validation_3rd: str = ""  # P: 3ì°¨ê²€ì¦ê°’ (ë§í¬ ìˆ˜ì§‘)
    validation_4th: str = ""  # Q: 4ì°¨ê²€ì¦ê°’ (ë³‘ë ¬ í¬ë¡¤ë§)
    validation_5th: str = ""  # R: 5ì°¨ê²€ì¦ê°’ (AI ê¸°ê´€ëª… ë„ì¶œ)
    validation_6th: str = ""  # S: 6ì°¨ê²€ì¦ê°’ (ì¢…í•© ë§¤ì¹­)
    
    # T~X ì»¬ëŸ¼: ì¶”ì¶œ ë§í¬ë“¤
    extracted_links: List[str] = field(default_factory=list)
    
    # Y~AC ì»¬ëŸ¼: ë§í¬ë³„ AI ì‘ë‹µ
    ai_responses: List[str] = field(default_factory=list)
    
    # ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    processing_time: float = 0.0
    error_message: str = ""
    success: bool = False


class CompCrawlingSystem:
    """SystemAnalyzer ê¸°ë°˜ ì§„ë³´ëœ í¬ë¡¤ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.setup_logging()
        self.load_environment()
        self.initialize_components()
        self.setup_headless_toggle()
        
        self.logger.info("ğŸš€ CompCrawlingSystem ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        # logs ë””ë ‰í† ë¦¬ ìƒì„±
        logs_dir = "logs"
        if not os.path.exists(logs_dir):
            os.makedirs(logs_dir)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'{logs_dir}/comp_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("CompCrawling")
    
    def load_environment(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        load_dotenv()
        
        # Gemini API í‚¤ ë¡œë“œ (4ê°œ)
        self.gemini_keys = []
        for i in range(1, 5):
            key = os.getenv(f'GEMINI_API_KEY_{i}')
            if key:
                self.gemini_keys.append(key)
        
        if not self.gemini_keys:
            raise ValueError("âŒ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.logger.info(f"ğŸ”‘ Gemini API í‚¤ {len(self.gemini_keys)}ê°œ ë¡œë“œ ì™„ë£Œ")
    
    def initialize_components(self):
        """í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # SystemAnalyzerë¡œ ë™ì  ì›Œì»¤ ê´€ë¦¬ (ë‹¨ì¼ ì´ˆê¸°í™”)
        self.system_analyzer = SystemAnalyzer(self.logger)
        self.system_analyzer.start_monitoring()
        # ì—„ê²©í•œ ì œí•œ: ìµœëŒ€ 4ê°œ ì›Œì»¤ë¡œ ê³ ì •
        self.max_workers = 4
        
        # ì„±ëŠ¥ ê´€ë¦¬ì
        self.performance_manager = PerformanceManager()
        self.crawling_settings = CrawlingSettings()
        
        # UA ë¡œí…Œì´í„°
        self.ua_rotator = UserAgentRotator(self.logger)
        
        # ê²€ì¦ ì—”ì§„ë“¤
        self.phone_validator = PhoneValidator()
        self.verification_engine = VerificationEngine()
        self.google_search_engine = GoogleSearchEngine()
        self.homepage_crawler = HomepageCrawler()
        
        # Valid3.py ë°©ì‹ì˜ ë“œë¼ì´ë²„ ê´€ë¦¬ (ì›Œì»¤ë³„ WebDriverManager + í¬íŠ¸ ê´€ë¦¬)
        self.web_driver_managers = {}  # ì›Œì»¤ë³„ WebDriverManager ë”•ì…”ë„ˆë¦¬
        self.driver_lock = threading.Lock()  # ë“œë¼ì´ë²„ ìƒì„±/í•´ì œ ì‹œ ë™ê¸°í™”
        self.max_pool_size = 4  # ì—„ê²©íˆ 4ê°œë¡œ ê³ ì •
        
        # í¬íŠ¸ ê´€ë¦¬ì ì¶”ê°€
        self.port_manager = AdvancedPortManager(self.logger)
        
        # AI ëª¨ë¸ ê´€ë¦¬ì (í‚¤ ë¡œí…Œì´ì…˜)
        self.ai_manager = AIModelManager()
        self.current_key_index = 0
        
        # ë°ì´í„° ì²˜ë¦¬
        self.data_processor = DataProcessor()
        self.excel_processor = ExcelProcessor()
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_headless = False  # ê¸°ë³¸ê°’: í—¤ë“œë¦¬ìŠ¤ OFF
        self.processed_count = 0
        self.batch_size = 20  # ë°°ì¹˜ í¬ê¸°ë„ ì¤„ì—¬ì„œ ì•ˆì •ì„± í™•ë³´
        
        self.logger.info("âš™ï¸ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ”§ ì—„ê²©í•œ ì œí•œ: ìµœëŒ€ ì›Œì»¤ {self.max_workers}ê°œ, ë“œë¼ì´ë²„ í’€ {self.max_pool_size}ê°œ ê³ ì •")
        self.logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ (ì•ˆì •ì„± ìš°ì„ )")
        self.logger.info(f"ğŸ›¡ï¸ ë“œë¼ì´ë²„ ë¬´í•œì¦ì‹ ë°©ì§€: ìƒì„± ì™„ë£Œ í›„ ì¬ì‚¬ìš© ëª¨ë“œ")
    
    def setup_headless_toggle(self):
        """ì‹¤ì‹œê°„ í—¤ë“œë¦¬ìŠ¤ í† ê¸€ ì„¤ì •"""
        self.headless_lock = threading.Lock()
        
        # í—¤ë“œë¦¬ìŠ¤ í† ê¸€ í•¨ìˆ˜ (ìˆ˜ë™ í˜¸ì¶œìš©)
        def toggle_headless():
            with self.headless_lock:
                self.is_headless = not self.is_headless
                mode = "ON" if self.is_headless else "OFF"
                self.logger.info(f"ğŸ–¥ï¸ í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ {mode} ì „í™˜")
                
                # ê¸°ì¡´ ë“œë¼ì´ë²„ë“¤ ì¬ì‹œì‘ (ìƒˆ í—¤ë“œë¦¬ìŠ¤ ì„¤ì • ì ìš©)
                self._restart_all_drivers()
        
        # í† ê¸€ í•¨ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (ë‚˜ì¤‘ì— ìˆ˜ë™ í˜¸ì¶œ ê°€ëŠ¥)
        self.toggle_headless = toggle_headless
        
        # í‚¤ë³´ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ë„ ë™ì‘í•˜ë„ë¡ ìˆ˜ì •
        try:
            import keyboard
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‚¤ ì…ë ¥ ê°ì§€
            def key_listener():
                try:
                    while True:
                        if keyboard.is_pressed('h'):
                            toggle_headless()
                            time.sleep(1)  # ì—°ì† ì…ë ¥ ë°©ì§€
                        time.sleep(0.1)
                except:
                    pass  # í‚¤ë³´ë“œ í›„í‚¹ ì‹¤íŒ¨ì‹œ ë¬´ì‹œ
            
            threading.Thread(target=key_listener, daemon=True).start()
            self.logger.info("âŒ¨ï¸ í—¤ë“œë¦¬ìŠ¤ í† ê¸€ ë¦¬ìŠ¤ë„ˆ í™œì„±í™” ('h' í‚¤ë¡œ ì „í™˜)")
        except ImportError:
            self.logger.info("âŒ¨ï¸ keyboard ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ìˆ˜ë™ í† ê¸€ë§Œ ì§€ì› (system.toggle_headless() í˜¸ì¶œ)")
    
    def _restart_all_drivers(self):
        """Valid3.py ë°©ì‹: ëª¨ë“  ì›Œì»¤ ë“œë¼ì´ë²„ ì¬ì‹œì‘"""
        with self.driver_lock:
            old_managers_count = len(self.web_driver_managers)
            
            # ëª¨ë“  ê¸°ì¡´ WebDriverManager ì •ë¦¬
            self.cleanup_all_drivers()
            
            self.logger.info(f"ğŸ”„ {old_managers_count}ê°œ WebDriverManager ì¬ì‹œì‘ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì ìš©)")
    

    
    def get_driver_for_worker(self, worker_id: int):
        """Valid3.py ë°©ì‹: ì›Œì»¤ë³„ WebDriverManager ì¸ìŠ¤í„´ìŠ¤ íšë“ (ì—„ê²©íˆ 4ê°œ ì œí•œ + ë“œë¼ì´ë²„ ì¬ì‚¬ìš©)"""
        with self.driver_lock:
            # ì›Œì»¤ IDë¥¼ 0~3ìœ¼ë¡œ ì œí•œ (4ê°œë¡œ ì—„ê²©íˆ ê³ ì •)
            limited_worker_id = worker_id % 4
            
            # ê¸°ì¡´ WebDriverManager í™•ì¸ ë° ì¬ì‚¬ìš©
            if limited_worker_id in self.web_driver_managers:
                web_manager = self.web_driver_managers[limited_worker_id]
                
                # ê¸°ì¡´ ë“œë¼ì´ë²„ê°€ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸
                if hasattr(web_manager, 'driver') and web_manager.driver:
                    try:
                        # ë“œë¼ì´ë²„ ìƒíƒœ ì²´í¬ (ê°„ë‹¨í•œ ëª…ë ¹ ì‹¤í–‰)
                        web_manager.driver.execute_script("return document.readyState;")
                        self.logger.debug(f"ğŸ”„ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}): ê¸°ì¡´ ë“œë¼ì´ë²„ ì¬ì‚¬ìš©")
                        return web_manager
                    except:
                        # ë“œë¼ì´ë²„ê°€ ì£½ì—ˆìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•  ì˜ˆì •
                        self.logger.debug(f"âš ï¸ ì›Œì»¤ {limited_worker_id}: ê¸°ì¡´ ë“œë¼ì´ë²„ ë¹„ì •ìƒ, ì¬ìƒì„± í•„ìš”")
                        pass
                
                # WebDriverManagerëŠ” ìˆì§€ë§Œ ë“œë¼ì´ë²„ê°€ ì—†ìœ¼ë©´ ì¬ì‚¬ìš©
                self.logger.debug(f"ğŸ”„ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}): ê¸°ì¡´ WebDriverManager ì¬ì‚¬ìš©")
                return web_manager
            else:
                # ìƒˆë¡œìš´ WebDriverManager ìƒì„± (ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ)
                if len(self.web_driver_managers) >= 4:
                    # ì´ë¯¸ 4ê°œê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ê²ƒ ì¬ì‚¬ìš© (Round-robin)
                    existing_worker_id = list(self.web_driver_managers.keys())[limited_worker_id % len(self.web_driver_managers)]
                    self.logger.debug(f"ğŸ”„ ì›Œì»¤ {worker_id} -> ê¸°ì¡´ ì›Œì»¤ {existing_worker_id} ì¬ì‚¬ìš© (4ê°œ ì œí•œ)")
                    return self.web_driver_managers[existing_worker_id]
                
                self.logger.debug(f"ğŸ”§ ì›Œì»¤ {limited_worker_id} WebDriverManager ìƒˆë¡œ ìƒì„± ì¤‘... ({len(self.web_driver_managers)+1}/4)")
                new_manager = WebDriverManager(logger=self.logger)
                self.web_driver_managers[limited_worker_id] = new_manager
                self.logger.debug(f"âœ… ì›Œì»¤ {limited_worker_id} WebDriverManager ìƒì„± ì™„ë£Œ")
                
                return new_manager
    
    def get_worker_driver(self, worker_id: int):
        """ì›Œì»¤ë³„ ì‹¤ì œ ë“œë¼ì´ë²„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ë“œë¼ì´ë²„ ì¬ì‚¬ìš© + í¬íŠ¸ ê´€ë¦¬)"""
        try:
            # WebDriverManager íšë“
            web_manager = self.get_driver_for_worker(worker_id)
            limited_worker_id = worker_id % 4  # 0~3ìœ¼ë¡œ ì œí•œ
            
            # ê¸°ì¡´ ë“œë¼ì´ë²„ê°€ ì‚´ì•„ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜ (ë¬´í•œì¦ì‹ ë°©ì§€!)
            if hasattr(web_manager, 'driver') and web_manager.driver:
                try:
                    # ë“œë¼ì´ë²„ ìƒíƒœ ì²´í¬
                    web_manager.driver.execute_script("return document.readyState;")
                    self.logger.debug(f"â™»ï¸ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}): ê¸°ì¡´ ë“œë¼ì´ë²„ ì¬ì‚¬ìš© (ë¬´í•œì¦ì‹ ë°©ì§€)")
                    return web_manager.driver
                except:
                    # ë“œë¼ì´ë²„ê°€ ì£½ì—ˆìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                    self.logger.debug(f"ğŸ’€ ì›Œì»¤ {limited_worker_id}: ê¸°ì¡´ ë“œë¼ì´ë²„ ë¹„ì •ìƒ, ìƒˆë¡œ ìƒì„±")
                    web_manager.driver = None
            
            # ìƒˆ ë“œë¼ì´ë²„ ìƒì„±ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í¬íŠ¸ í• ë‹¹
            assigned_port = self.port_manager.allocate_port(limited_worker_id)
            
            # í—¤ë“œë¦¬ìŠ¤ ì„¤ì •ì— ë”°ë¼ ë“œë¼ì´ë²„ ìƒì„±
            with self.headless_lock:
                headless = self.is_headless
            
            try:
                if headless:
                    # í—¤ë“œë¦¬ìŠ¤ ë“œë¼ì´ë²„ (í¬íŠ¸ ì§€ì •)
                    driver = web_manager._try_headless_chrome(limited_worker_id, assigned_port)
                else:
                    # ì¼ë°˜ ë“œë¼ì´ë²„ (ë´‡ ê°ì§€ ìš°íšŒ, í¬íŠ¸ ì§€ì •)
                    driver = web_manager.create_bot_evasion_driver(limited_worker_id, assigned_port)
                
                # WebDriverManagerì— ë“œë¼ì´ë²„ ì €ì¥ (ì¬ì‚¬ìš©ì„ ìœ„í•´)
                web_manager.driver = driver
                
                # User-Agent ì„¤ì •
                try:
                    user_agent = self.ua_rotator.get_random_user_agent()
                    driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                        "userAgent": user_agent
                    })
                except Exception as ua_error:
                    self.logger.warning(f"UA ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œ): {ua_error}")
                
                self.logger.info(f"ğŸ†• ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}) ìƒˆ ë“œë¼ì´ë²„ ìƒì„± ({'í—¤ë“œë¦¬ìŠ¤' if headless else 'ì¼ë°˜'}, í¬íŠ¸:{assigned_port})")
                return driver
                
            except Exception as driver_error:
                # ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨ì‹œ í¬íŠ¸ í•´ì œ
                self.port_manager.release_port(assigned_port, limited_worker_id)
                self.logger.error(f"âŒ ì›Œì»¤ {worker_id} ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨, í¬íŠ¸ {assigned_port} í•´ì œ: {driver_error}")
                
                # í¬íŠ¸ë¥¼ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ê³  ì¬ì‹œë„
                self.port_manager.blacklist_port(assigned_port, f"ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {driver_error}")
                
                # ë‹¤ë¥¸ í¬íŠ¸ë¡œ ì¬ì‹œë„ (1íšŒë§Œ)
                retry_port = self.port_manager.allocate_port(limited_worker_id)
                if retry_port != assigned_port:
                    self.logger.warning(f"ğŸ”„ ì›Œì»¤ {worker_id} ë‹¤ë¥¸ í¬íŠ¸ë¡œ ì¬ì‹œë„: {retry_port}")
                    try:
                        if headless:
                            driver = web_manager._try_headless_chrome(limited_worker_id, retry_port)
                        else:
                            driver = web_manager.create_bot_evasion_driver(limited_worker_id, retry_port)
                        
                        # ì¬ì‹œë„ ì„±ê³µì‹œ WebDriverManagerì— ì €ì¥
                        web_manager.driver = driver
                        self.logger.info(f"âœ… ì›Œì»¤ {worker_id} ì¬ì‹œë„ ì„±ê³µ (í¬íŠ¸:{retry_port})")
                        return driver
                    except Exception as retry_error:
                        self.port_manager.release_port(retry_port, limited_worker_id)
                        self.port_manager.blacklist_port(retry_port, f"ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                        raise
                else:
                    raise
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œì»¤ {worker_id} ë“œë¼ì´ë²„ íšë“ ì‹¤íŒ¨: {e}")
            raise
    
    def load_csv_data(self, file_path: str) -> pd.DataFrame:
        """CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            # CSV ë¡œë“œ
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ğŸ“Š CSV ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)
            df.columns = [col.strip() for col in df.columns]
            
            # ì»¬ëŸ¼ ë§¤í•‘
            column_mapping = {
                'ì‹œë„': 'region',
                'ì‹œêµ°êµ¬': 'district', 
                'ìë©´ë™': 'institution_name',
                'ì£¼    ì†Œ': 'address',
                'ì „í™”ë²ˆí˜¸': 'phone',
                'íŒ©ìŠ¤ë²ˆí˜¸': 'fax'
            }
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë§¤í•‘
            actual_mapping = {}
            for old_name, new_name in column_mapping.items():
                if old_name in df.columns:
                    actual_mapping[old_name] = new_name
            
            df = df.rename(columns=actual_mapping)
            
            # ë°ì´í„° ì •ë¦¬
            for col in ['region', 'district', 'institution_name', 'address']:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.strip()
                    df[col] = df[col].replace('nan', '').replace('#N/A', '')
            
            # ì „í™”/íŒ©ìŠ¤ ì •ê·œí™”
            for col in ['phone', 'fax']:
                if col in df.columns:
                    df[col] = df[col].astype(str).apply(self._normalize_phone_number)
            
            # ë¹ˆ í–‰ ì œê±°
            df = df.dropna(subset=['institution_name', 'fax'], how='all')
            
            self.logger.info(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}í–‰")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _normalize_phone_number(self, phone: str) -> str:
        """ì „í™”ë²ˆí˜¸ ì •ê·œí™”"""
        if not phone or phone in ['nan', '#N/A', '']:
            return ""
        
        # ìˆ«ìë§Œ ì¶”ì¶œ
        import re
        digits = re.sub(r'[^\d]', '', str(phone))
        
        if len(digits) < 8:
            return ""
        
        return digits
    
    def process_validation_pipeline(self, row_data: pd.Series, row_index: int, worker_id: int) -> CompValidationResult:
        """ë‹¨ì¼ í–‰ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        start_time = time.time()
        
        result = CompValidationResult(
            row_index=row_index,
            region=row_data.get('region', ''),
            district=row_data.get('district', ''), 
            institution_name=row_data.get('institution_name', ''),
            address=row_data.get('address', ''),
            phone=row_data.get('phone', ''),
            fax=row_data.get('fax', '')
        )
        
        try:
            # 1ì°¨ ê²€ì¦: ì§€ì—­ë²ˆí˜¸ ë§¤ì¹­
            self._validate_stage1(result, worker_id)
            
            # 2ì°¨ ê²€ì¦: êµ¬ê¸€ ê²€ìƒ‰
            self._validate_stage2(result, worker_id)
            
            # 3ì°¨ ê²€ì¦: ë§í¬ ìˆ˜ì§‘  
            self._validate_stage3(result, worker_id)
            
            # 4ì°¨ ê²€ì¦: ë³‘ë ¬ í¬ë¡¤ë§
            self._validate_stage4(result, worker_id)
            
            # 5ì°¨ ê²€ì¦: AI ê¸°ê´€ëª… ë„ì¶œ
            self._validate_stage5(result, worker_id)
            
            # 6ì°¨ ê²€ì¦: ì¢…í•© ë§¤ì¹­
            self._validate_stage6(result, worker_id)
            
            result.success = True
            
        except Exception as e:
            self.logger.error(f"âŒ í–‰ {row_index} ê²€ì¦ ì‹¤íŒ¨: {e}")
            result.error_message = str(e)
            result.success = False
        
        result.processing_time = time.time() - start_time
        return result
    
    def _validate_stage1(self, result: CompValidationResult, worker_id: int):
        """1ì°¨ ê²€ì¦: ì§€ì—­ë²ˆí˜¸ ë§¤ì¹­"""
        try:
            if not result.fax or not result.address:
                result.validation_1st = "ë°ì´í„° ë¶€ì¡±"
                return
            
            # ì •ê·œí™”ëœ íŒ©ìŠ¤ë²ˆí˜¸ë¡œ ì§€ì—­ ì¼ì¹˜ì„± ê²€ì‚¬
            is_match = self.phone_validator.is_regional_match(result.fax, result.address)
            
            if is_match:
                result.validation_1st = "ì§€ì—­ ì¼ì¹˜"
            else:
                result.validation_1st = "ì§€ì—­ ë¶ˆì¼ì¹˜"
                
        except Exception as e:
            result.validation_1st = f"ê²€ì¦ ì˜¤ë¥˜: {e}"
    
    def _validate_stage2(self, result: CompValidationResult, worker_id: int):
        """2ì°¨ ê²€ì¦: êµ¬ê¸€ ê²€ìƒ‰ (UA íšŒí”¼) - search_logic.txt 4-8í–‰ êµ¬í˜„"""
        try:
            driver = self.get_worker_driver(worker_id)
            
            # íŒ©ìŠ¤ë²ˆí˜¸ë¡œ êµ¬ê¸€ ê²€ìƒ‰ ("{ numbers } íŒ©ìŠ¤ë²ˆí˜¸ëŠ” ì–´ë””ê¸°ê´€?")
            search_query = f"fax {result.fax}"
            
            # Google ê²€ìƒ‰ ì‹œë„
            search_results = self.google_search_engine.search(
                query=search_query,
                driver=driver,
                max_results=5
            )
            
            # ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ HTTP ìš”ì²­ìœ¼ë¡œ Naver, Daum ì¶”ê°€ ê²€ìƒ‰
            if not search_results:
                search_results = self._fallback_search_engines(search_query, result.fax)
            
            if search_results:
                result.validation_2nd = f"ê²€ìƒ‰ ì„±ê³µ: {len(search_results)}ê°œ ê²°ê³¼"
                
                # ìŠ¤ë‹ˆí«ì—ì„œ ê´€ë ¨ ë§í¬ë“¤ ì¶”ì¶œí•˜ì—¬ ì €ì¥ (ìµœëŒ€ 5ê°œ)
                extracted_links = self._extract_links_from_search_results(search_results)
                
                # ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ ì‹œë„
                first_result = search_results[0]
                institution = self._extract_institution_from_snippet(
                    first_result.get('snippet', ''), 
                    result.fax
                )
                
                if institution:
                    result.fax_real_institution = institution
                    result.fax_verified = result.fax
                    
                # ì „í™”ë²ˆí˜¸ë„ ë™ì¼í•˜ê²Œ ê²€ìƒ‰í•˜ì—¬ G/H ì»¬ëŸ¼ ì±„ìš°ê¸°
                if result.phone:
                    phone_institution, phone_verified = self._search_phone_number(result.phone, worker_id)
                    if phone_institution:
                        result.phone_real_institution = phone_institution
                        result.phone_verified = phone_verified
            else:
                result.validation_2nd = "ëª¨ë“  ê²€ìƒ‰ì—”ì§„ì—ì„œ ê²°ê³¼ ì—†ìŒ"
                
        except Exception as e:
            result.validation_2nd = f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}"
    
    def _validate_stage3(self, result: CompValidationResult, worker_id: int):
        """3ì°¨ ê²€ì¦: ë§í¬ ìˆ˜ì§‘ (ìƒìœ„ 5ê°œ) - search_logic.txt 10-13í–‰ êµ¬í˜„"""
        try:
            # 2ì°¨ ê²€ì¦ì—ì„œ ì´ë¯¸ ë§í¬ê°€ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©´ ì¬ì‚¬ìš©
            if hasattr(result, '_stage2_links') and result._stage2_links:
                result.extracted_links = result._stage2_links[:5]
                result.validation_3rd = f"2ì°¨ì—ì„œ ìˆ˜ì§‘ëœ ë§í¬ {len(result.extracted_links)}ê°œ í™œìš©"
                return
            
            driver = self.get_worker_driver(worker_id)
            
            # ë” êµ¬ì²´ì ì¸ ê²€ìƒ‰ìœ¼ë¡œ ë§í¬ ìˆ˜ì§‘
            search_queries = [
                f"fax {result.fax}",
                f"{result.fax} {result.institution_name}",
                f"{result.institution_name} {result.district} íŒ©ìŠ¤ë²ˆí˜¸"
            ]
            
            all_links = []
            
            for query in search_queries:
                if len(all_links) >= 5:
                    break
                    
                search_results = self.google_search_engine.search(
                    query=query,
                    driver=driver,
                    max_results=3
                )
                
                for res in search_results:
                    url = res.get('url', '')
                    if url and url.startswith('http') and url not in all_links:
                        all_links.append(url)
                        if len(all_links) >= 5:
                            break
            
            result.extracted_links = all_links[:5]
            
            if result.extracted_links:
                result.validation_3rd = f"ë§í¬ {len(result.extracted_links)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
            else:
                result.validation_3rd = "ìœ íš¨í•œ ë§í¬ ìˆ˜ì§‘ ì‹¤íŒ¨"
                
        except Exception as e:
            result.validation_3rd = f"ë§í¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}"
    
    def _validate_stage4(self, result: CompValidationResult, worker_id: int):
        """4ì°¨ ê²€ì¦: ë³‘ë ¬ í¬ë¡¤ë§ - search_logic.txt 10-14í–‰ êµ¬í˜„"""
        try:
            if not result.extracted_links:
                result.validation_4th = "í¬ë¡¤ë§í•  ë§í¬ ì—†ìŒ"
                return
            
            # ì—„ê²©íˆ 4ê°œë¡œ ì œí•œëœ ì›Œì»¤ ì‚¬ìš©
            max_workers = min(len(result.extracted_links), 4)
            
            # ë³‘ë ¬ í¬ë¡¤ëŸ¬ í™œì„±í™”: ê° ì›Œì»¤ê°€ ë§í¬ë¡œ ë“¤ì–´ê°
            crawl_results = []
            confidence_scores = []
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_link = {
                    executor.submit(self._advanced_crawl_single_link, link, result.fax, result.institution_name, worker_id + i): link
                    for i, link in enumerate(result.extracted_links)
                }
                
                for future in as_completed(future_to_link):
                    link = future_to_link[future]
                    try:
                        crawl_data = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                        crawl_results.append(crawl_data)
                        confidence_scores.append(crawl_data.get('confidence_score', 0.0))
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ë§í¬ í¬ë¡¤ë§ ì‹¤íŒ¨ {link}: {e}")
                        crawl_results.append({
                            'url': link, 
                            'error': str(e),
                            'confidence_score': 0.0
                        })
                        confidence_scores.append(0.0)
            
            # í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„ ë° ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            success_count = sum(1 for r in crawl_results if 'error' not in r)
            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            result.validation_4th = f"í¬ë¡¤ë§: {success_count}/{len(result.extracted_links)} ì„±ê³µ (ì‹ ë¢°ë„: {avg_confidence:.1f}%)"
            
            # í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ resultì— ì €ì¥ (5ì°¨ ê²€ì¦ìš©)
            result._crawled_data = crawl_results
            result._avg_confidence = avg_confidence
            
            # AI ì‘ë‹µì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            self._prepare_ai_responses(result, crawl_results)
            
        except Exception as e:
            result.validation_4th = f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}"
    
    def _crawl_single_link(self, url: str, fax: str, institution: str) -> Dict:
        """ë‹¨ì¼ ë§í¬ í¬ë¡¤ë§"""
        try:
            # VerificationEngineìœ¼ë¡œ ê³ ê¸‰ íŒŒì‹±
            parsed_data = self.verification_engine.parse_homepage(
                url=url,
                target_phone=fax,
                institution_name=institution
            )
            
            return {
                'url': url,
                'title': parsed_data.get('title', ''),
                'content': parsed_data.get('content', ''),
                'phone_numbers': parsed_data.get('phone_numbers', []),
                'confidence': parsed_data.get('confidence_score', 0.0)
            }
            
        except Exception as e:
            return {'url': url, 'error': str(e)}
    
    def _prepare_ai_responses(self, result: CompValidationResult, crawl_results: List[Dict]):
        """AI ì‘ë‹µ ì¤€ë¹„ (ê° ë§í¬ë³„)"""
        ai_responses = []
        
        for i, crawl_data in enumerate(crawl_results):
            try:
                if 'error' in crawl_data:
                    ai_responses.append(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {crawl_data['error']}")
                    continue
                
                # AIì—ê²Œ ë¶„ì„ ìš”ì²­
                context = f"""
                URL: {crawl_data['url']}
                ì œëª©: {crawl_data.get('title', '')}
                ë‚´ìš©: {crawl_data.get('content', '')[:1000]}...
                
                ì°¾ëŠ” íŒ©ìŠ¤ë²ˆí˜¸: {result.fax}
                ì˜ˆìƒ ê¸°ê´€: {result.institution_name}
                """
                
                ai_response = self._get_ai_analysis(context, result.fax, result.institution_name)
                ai_responses.append(ai_response)
                
            except Exception as e:
                ai_responses.append(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # 5ê°œê¹Œì§€ íŒ¨ë”©
        while len(ai_responses) < 5:
            ai_responses.append("")
        
        result.ai_responses = ai_responses[:5]
    
    def _get_ai_analysis(self, context: str, fax: str, institution: str) -> str:
        """AI ë¶„ì„ ìš”ì²­ (í‚¤ ë¡œí…Œì´ì…˜)"""
        try:
            # API í‚¤ ë¡œí…Œì´ì…˜
            api_key = self.gemini_keys[self.current_key_index % len(self.gemini_keys)]
            self.current_key_index += 1
            
            prompt = f"""
            ë‹¤ìŒ ì›¹í˜ì´ì§€ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ íŒ©ìŠ¤ë²ˆí˜¸ {fax}ê°€ {institution}ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:
            
            {context}
            
            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€:
            1. ê´€ë ¨ì„±: (ë†’ìŒ/ë³´í†µ/ë‚®ìŒ/ì—†ìŒ)
            2. ë°œê²¬ëœ ê¸°ê´€ëª…: 
            3. ë°œê²¬ëœ íŒ©ìŠ¤ë²ˆí˜¸:
            4. ì‹ ë¢°ë„: (0-100%)
            """
            
            # AIModelManager ì‚¬ìš©
            response = self.ai_manager.get_gemini_response(prompt, api_key=api_key)
            return response[:200]  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
            
        except Exception as e:
            return f"AI ë¶„ì„ ì˜¤ë¥˜: {e}"
    
    def _validate_stage5(self, result: CompValidationResult, worker_id: int):
        """5ì°¨ ê²€ì¦: AI ê¸°ê´€ëª… ë„ì¶œ - search_logic.txt 16-17í–‰ êµ¬í˜„"""
        try:
            # ë„ì¶œëœ íŒ©ìŠ¤ë²ˆí˜¸ -> { numbers } íŒ©ìŠ¤ë²ˆí˜¸ ì–´ë””ê¸°ê´€? -> 3ì°¨ ê²€ì¦ê°’ ë§¤ì¹­ -> AI íŒë‹¨ -> ê¸°ê´€ëª… ë„ì¶œ
            
            # 4ì°¨ì—ì„œ ì¶”ì¶œëœ íŒ©ìŠ¤ë²ˆí˜¸ë“¤ ìˆ˜ì§‘
            discovered_fax_numbers = self._extract_fax_numbers_from_crawled_data(result)
            
            if discovered_fax_numbers:
                # ê° ë°œê²¬ëœ íŒ©ìŠ¤ë²ˆí˜¸ë¡œ ì—­ê²€ìƒ‰
                reverse_search_results = []
                for fax_num in discovered_fax_numbers:
                    reverse_result = self._reverse_search_fax_to_institution(fax_num, worker_id)
                    reverse_search_results.append(reverse_result)
                
                # AIë¡œ 3ì°¨ ê²€ì¦ê°’ê³¼ ë§¤ì¹­ ë¶„ì„
                best_institution = self._ai_analyze_institution_matching(
                    result.fax, 
                    result.institution_name,
                    result.extracted_links,
                    reverse_search_results,
                    getattr(result, '_crawled_data', [])
                )
                
                if best_institution:
                    # ê²€ì¦ëœ ì‹¤ì œ ê¸°ê´€ëª… ì—…ë°ì´íŠ¸
                    result.fax_real_institution = best_institution
                    result.validation_5th = f"AI ê¸°ê´€ëª… ë„ì¶œ: {best_institution}"
                else:
                    result.validation_5th = "AI ê¸°ê´€ëª… ë„ì¶œ ì‹¤íŒ¨"
            else:
                result.validation_5th = "4ì°¨ì—ì„œ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ ì—†ìŒ"
                
        except Exception as e:
            result.validation_5th = f"AI ë„ì¶œ ì˜¤ë¥˜: {e}"
    
    def _validate_stage6(self, result: CompValidationResult, worker_id: int):
        """6ì°¨ ê²€ì¦: ì¢…í•© ë§¤ì¹­ - search_logic.txt 19-21í–‰ êµ¬í˜„"""
        try:
            # { ê¸°ê´€ëª… } íŒ©ìŠ¤ë²ˆí˜¸ ê²€ìƒ‰ -> 2/3/4/5 ì°¨ ê²€ì¦ê°’ê³¼ ì™„ë²½í•˜ê²Œ AIì™€ ë§¤ì¹­ì‹œ ê¸°ê´€ëª… ë„ì¶œ
            
            if not result.fax_real_institution:
                result.validation_6th = "ì§ì ‘ ê²€ìƒ‰ ìš”ë§, ê²€ìƒ‰ ë° AIê²€ì¦ì‹¤íŒ¨"
                return
            
            # ë„ì¶œëœ ê¸°ê´€ëª…ìœ¼ë¡œ ì—­ê²€ìƒ‰í•˜ì—¬ íŒ©ìŠ¤ë²ˆí˜¸ í™•ì¸
            final_institution = result.fax_real_institution
            reverse_fax_search = self._search_institution_fax(final_institution, result.fax, worker_id)
            
            # ëª¨ë“  ê²€ì¦ ë‹¨ê³„ ë°ì´í„° ìˆ˜ì§‘
            all_validation_data = {
                'stage1': result.validation_1st,
                'stage2': result.validation_2nd,
                'stage3': result.validation_3rd,
                'stage4': result.validation_4th,
                'stage5': result.validation_5th,
                'extracted_links': result.extracted_links,
                'ai_responses': result.ai_responses,
                'crawled_data': getattr(result, '_crawled_data', []),
                'confidence': getattr(result, '_avg_confidence', 0.0)
            }
            
            # AIë¡œ ì™„ë²½ ë§¤ì¹­ ë¶„ì„
            perfect_match_result = self._ai_perfect_matching_analysis(
                result.fax,
                result.institution_name,
                final_institution,
                all_validation_data,
                reverse_fax_search
            )
            
            # ìµœì¢… íŒì •
            if perfect_match_result.get('is_perfect_match', False):
                confidence = perfect_match_result.get('confidence', 0)
                result.validation_6th = f"ì™„ë²½ ë§¤ì¹­ ì„±ê³µ (ì‹ ë¢°ë„: {confidence}%)"
                
                # ìµœì¢… ê²€ì¦ëœ ë°ì´í„° ì—…ë°ì´íŠ¸
                result.fax_verified = perfect_match_result.get('verified_fax', result.fax)
                result.fax_real_institution = perfect_match_result.get('verified_institution', final_institution)
            else:
                failure_reason = perfect_match_result.get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                result.validation_6th = f"ì§ì ‘ ê²€ìƒ‰ ìš”ë§: {failure_reason}"
                
        except Exception as e:
            result.validation_6th = f"ì¢…í•© ë§¤ì¹­ ì˜¤ë¥˜: {e}"
    
    def _extract_institution_from_snippet(self, snippet: str, fax: str) -> str:
        """ìŠ¤ë‹ˆí«ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ê¸°ê´€ëª… ì¶”ì¶œ ë¡œì§
        keywords = ['ì„¼í„°', 'ì£¼ë¯¼ì„¼í„°', 'êµ¬ì²­', 'ì‹œì²­', 'ë™', 'ë©´', 'ì']
        
        for keyword in keywords:
            if keyword in snippet:
                # í‚¤ì›Œë“œ ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ
                import re
                pattern = rf'[ê°€-í£\s]*{keyword}[ê°€-í£\s]*'
                match = re.search(pattern, snippet)
                if match:
                    return match.group().strip()
        
        return ""
    
    def _fallback_search_engines(self, query: str, fax: str) -> List[Dict]:
        """HTTP ìš”ì²­ìœ¼ë¡œ Naver, Daum ì¶”ê°€ ê²€ìƒ‰"""
        try:
            import requests
            from bs4 import BeautifulSoup
            
            results = []
            
            # UA ë¡œí…Œì´ì…˜ ì ìš©
            headers = {'User-Agent': self.ua_rotator.get_random_user_agent()}
            
            # Naver ê²€ìƒ‰
            try:
                naver_url = f"https://search.naver.com/search.naver?query={query}"
                response = requests.get(naver_url, headers=headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    # ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                    for item in soup.select('.total_tit')[:3]:
                        title = item.get_text(strip=True)
                        url = item.get('href', '')
                        if title and url:
                            results.append({'title': title, 'url': url, 'snippet': title})
            except:
                pass
            
            # Daum ê²€ìƒ‰
            try:
                daum_url = f"https://search.daum.net/search?q={query}"
                response = requests.get(daum_url, headers=headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    # ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                    for item in soup.select('.tit_main')[:3]:
                        title = item.get_text(strip=True)
                        url = item.get('href', '')
                        if title and url:
                            results.append({'title': title, 'url': url, 'snippet': title})
            except:
                pass
            
            return results
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í´ë°± ê²€ìƒ‰ ì—”ì§„ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_links_from_search_results(self, search_results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë§í¬ ì¶”ì¶œ"""
        links = []
        for result in search_results:
            url = result.get('url', '')
            if url and url.startswith('http') and url not in links:
                links.append(url)
                if len(links) >= 5:
                    break
        return links
    
    def _search_phone_number(self, phone: str, worker_id: int) -> Tuple[str, str]:
        """ì „í™”ë²ˆí˜¸ë¡œ ê¸°ê´€ ê²€ìƒ‰ (G/H ì»¬ëŸ¼ìš©)"""
        try:
            driver = self.get_worker_driver(worker_id)
            # í°ë”°ì˜´í‘œ ì—†ì´ ê²€ìƒ‰ì¿¼ë¦¬ ìƒì„±
            search_query = f"{phone} ì–´ë”” ì „í™”ë²ˆí˜¸"
            
            search_results = self.google_search_engine.search(
                query=search_query,
                driver=driver,
                max_results=3
            )
            
            if search_results:
                first_result = search_results[0]
                institution = self._extract_institution_from_snippet(
                    first_result.get('snippet', ''), 
                    phone
                )
                return institution, phone if institution else ""
            
            return "", ""
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return "", ""
    
    def _advanced_crawl_single_link(self, url: str, fax: str, institution: str, worker_id: int) -> Dict:
        """ê³ ê¸‰ ë‹¨ì¼ ë§í¬ í¬ë¡¤ë§ (BS4 + JS ë Œë”ë§ í´ë°±)"""
        try:
            # VerificationEngineìœ¼ë¡œ ê³ ê¸‰ íŒŒì‹± (BS4 â†’ Selenium í´ë°±)
            parsed_data = self.verification_engine.parse_homepage(
                url=url,
                target_phone=fax,
                institution_name=institution
            )
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence = self._calculate_link_confidence(parsed_data, fax, institution)
            
            return {
                'url': url,
                'title': parsed_data.get('title', ''),
                'content': parsed_data.get('content', ''),
                'phone_numbers': parsed_data.get('phone_numbers', []),
                'fax_numbers': parsed_data.get('fax_numbers', []),
                'institution_names': parsed_data.get('institution_names', []),
                'confidence_score': confidence,
                'parsing_method': parsed_data.get('method', 'bs4')
            }
            
        except Exception as e:
            return {'url': url, 'error': str(e), 'confidence_score': 0.0}
    
    def _calculate_link_confidence(self, parsed_data: Dict, target_fax: str, target_institution: str) -> float:
        """ë§í¬ í¬ë¡¤ë§ ê²°ê³¼ì˜ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        confidence = 0.0
        
        # íŒ©ìŠ¤ë²ˆí˜¸ ì¼ì¹˜ í™•ì¸
        fax_numbers = parsed_data.get('fax_numbers', [])
        if target_fax in fax_numbers:
            confidence += 50.0
        
        # ê¸°ê´€ëª… ìœ ì‚¬ë„ í™•ì¸
        institution_names = parsed_data.get('institution_names', [])
        for inst_name in institution_names:
            similarity = self._calculate_institution_similarity(target_institution, inst_name)
            confidence += similarity * 0.3
        
        # ì œëª©ì—ì„œ ê´€ë ¨ì„± í™•ì¸
        title = parsed_data.get('title', '')
        if target_institution in title:
            confidence += 20.0
        
        return min(confidence, 100.0)
    
    def _calculate_institution_similarity(self, original: str, extracted: str) -> float:
        """ê¸°ê´€ëª… ìœ ì‚¬ë„ ê³„ì‚°"""
        if not original or not extracted:
            return 0.0
        
        # ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ (Jaccard similarity)
        set1 = set(original)
        set2 = set(extracted)
        
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return (intersection / union * 100) if union > 0 else 0.0
    
    def _extract_fax_numbers_from_crawled_data(self, result: CompValidationResult) -> List[str]:
        """í¬ë¡¤ë§ëœ ë°ì´í„°ì—ì„œ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ"""
        fax_numbers = []
        crawled_data = getattr(result, '_crawled_data', [])
        
        for data in crawled_data:
            if 'error' not in data:
                # í¬ë¡¤ë§ëœ íŒ©ìŠ¤ë²ˆí˜¸ë“¤ ìˆ˜ì§‘
                fax_nums = data.get('fax_numbers', [])
                for fax in fax_nums:
                    normalized = self._normalize_phone_number(fax)
                    if normalized and normalized not in fax_numbers:
                        fax_numbers.append(normalized)
        
        return fax_numbers
    
    def _reverse_search_fax_to_institution(self, fax_number: str, worker_id: int) -> Dict:
        """íŒ©ìŠ¤ë²ˆí˜¸ë¡œ ê¸°ê´€ ì—­ê²€ìƒ‰"""
        try:
            driver = self.get_worker_driver(worker_id)
            search_query = f"fax {fax_number}"
            
            search_results = self.google_search_engine.search(
                query=search_query,
                driver=driver,
                max_results=3
            )
            
            institutions = []
            for result in search_results:
                snippet = result.get('snippet', '')
                institution = self._extract_institution_from_snippet(snippet, fax_number)
                if institution:
                    institutions.append(institution)
            
            return {
                'fax_number': fax_number,
                'found_institutions': institutions,
                'search_count': len(search_results)
            }
            
        except Exception as e:
            return {
                'fax_number': fax_number,
                'error': str(e),
                'found_institutions': []
            }
    
    def _ai_analyze_institution_matching(self, original_fax: str, original_institution: str, 
                                       extracted_links: List[str], reverse_results: List[Dict], 
                                       crawled_data: List[Dict]) -> str:
        """AIë¡œ ê¸°ê´€ëª… ë§¤ì¹­ ë¶„ì„"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = f"""
            ì›ë³¸ ì •ë³´:
            - íŒ©ìŠ¤ë²ˆí˜¸: {original_fax}
            - ì˜ˆìƒ ê¸°ê´€: {original_institution}
            
            í¬ë¡¤ë§ ê²°ê³¼:
            - ì¶”ì¶œëœ ë§í¬ ìˆ˜: {len(extracted_links)}
            - í¬ë¡¤ë§ ì„±ê³µ: {sum(1 for d in crawled_data if 'error' not in d)}ê°œ
            
            ì—­ê²€ìƒ‰ ê²°ê³¼:
            """
            
            for reverse_result in reverse_results:
                institutions = reverse_result.get('found_institutions', [])
                context += f"- {reverse_result['fax_number']}: {', '.join(institutions)}\n"
            
            prompt = f"""
            ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê¸°ê´€ëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”:
            
            {context}
            
            ë‹µë³€ í˜•ì‹:
            ê¸°ê´€ëª…: [ì„ íƒëœ ê¸°ê´€ëª…]
            ì‹ ë¢°ë„: [0-100]
            ì‚¬ìœ : [ì„ íƒ ì´ìœ ]
            """
            
            # API í‚¤ ë¡œí…Œì´ì…˜
            api_key = self.gemini_keys[self.current_key_index % len(self.gemini_keys)]
            self.current_key_index += 1
            
            response = self.ai_manager.get_gemini_response(prompt, api_key=api_key)
            
            # AI ì‘ë‹µì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ
            lines = response.split('\n')
            for line in lines:
                if line.startswith('ê¸°ê´€ëª…:'):
                    return line.replace('ê¸°ê´€ëª…:', '').strip()
            
            return ""
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI ê¸°ê´€ëª… ë¶„ì„ ì‹¤íŒ¨: {e}")
            return ""
    
    def _search_institution_fax(self, institution_name: str, target_fax: str, worker_id: int) -> Dict:
        """ê¸°ê´€ëª…ìœ¼ë¡œ íŒ©ìŠ¤ë²ˆí˜¸ ê²€ìƒ‰"""
        try:
            driver = self.get_worker_driver(worker_id)
            search_query = f"{institution_name} íŒ©ìŠ¤ë²ˆí˜¸"
            
            search_results = self.google_search_engine.search(
                query=search_query,
                driver=driver,
                max_results=5
            )
            
            found_fax_numbers = []
            for result in search_results:
                snippet = result.get('snippet', '')
                # ìŠ¤ë‹ˆí«ì—ì„œ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ
                import re
                fax_pattern = r'[\d\-\(\)\s]{8,}'
                matches = re.findall(fax_pattern, snippet)
                for match in matches:
                    normalized = self._normalize_phone_number(match)
                    if normalized and len(normalized) >= 8:
                        found_fax_numbers.append(normalized)
            
            # íƒ€ê²Ÿ íŒ©ìŠ¤ë²ˆí˜¸ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            is_match = target_fax in found_fax_numbers
            
            return {
                'institution': institution_name,
                'found_fax_numbers': found_fax_numbers,
                'target_fax': target_fax,
                'is_match': is_match,
                'confidence': 100 if is_match else 0
            }
            
        except Exception as e:
            return {
                'institution': institution_name,
                'error': str(e),
                'is_match': False
            }
    
    def _ai_perfect_matching_analysis(self, original_fax: str, original_institution: str, 
                                    ai_institution: str, all_validation_data: Dict, 
                                    reverse_fax_search: Dict) -> Dict:
        """AI ì™„ë²½ ë§¤ì¹­ ë¶„ì„"""
        try:
            context = f"""
            ì™„ë²½ ë§¤ì¹­ ë¶„ì„ ìš”ì²­:
            
            ì›ë³¸ ë°ì´í„°:
            - íŒ©ìŠ¤ë²ˆí˜¸: {original_fax}
            - ê¸°ê´€ëª…: {original_institution}
            
            AI ë„ì¶œ ê¸°ê´€ëª…: {ai_institution}
            
            ê²€ì¦ ë‹¨ê³„ë³„ ê²°ê³¼:
            - 1ì°¨ (ì§€ì—­ë§¤ì¹­): {all_validation_data['stage1']}
            - 2ì°¨ (êµ¬ê¸€ê²€ìƒ‰): {all_validation_data['stage2']}
            - 3ì°¨ (ë§í¬ìˆ˜ì§‘): {all_validation_data['stage3']}
            - 4ì°¨ (ë³‘ë ¬í¬ë¡¤ë§): {all_validation_data['stage4']}
            - 5ì°¨ (AIë¶„ì„): {all_validation_data['stage5']}
            
            ì—­ê²€ìƒ‰ ê²°ê³¼: {reverse_fax_search.get('is_match', False)}
            ì‹ ë¢°ë„: {all_validation_data.get('confidence', 0)}%
            """
            
            prompt = f"""
            ë‹¤ìŒ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì™„ë²½í•œ ë§¤ì¹­ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:
            
            {context}
            
            ë‹µë³€ í˜•ì‹:
            ì™„ë²½ë§¤ì¹­: [ì˜ˆ/ì•„ë‹ˆì˜¤]
            ì‹ ë¢°ë„: [0-100]
            ê²€ì¦ëœíŒ©ìŠ¤: [ìµœì¢… íŒ©ìŠ¤ë²ˆí˜¸]
            ê²€ì¦ëœê¸°ê´€: [ìµœì¢… ê¸°ê´€ëª…]
            ì‚¬ìœ : [íŒë‹¨ ê·¼ê±°]
            """
            
            # API í‚¤ ë¡œí…Œì´ì…˜
            api_key = self.gemini_keys[self.current_key_index % len(self.gemini_keys)]
            self.current_key_index += 1
            
            response = self.ai_manager.get_gemini_response(prompt, api_key=api_key)
            
            # ì‘ë‹µ íŒŒì‹±
            result = {
                'is_perfect_match': False,
                'confidence': 0,
                'verified_fax': original_fax,
                'verified_institution': ai_institution,
                'reason': 'ë¶„ì„ ì‹¤íŒ¨'
            }
            
            lines = response.split('\n')
            for line in lines:
                if line.startswith('ì™„ë²½ë§¤ì¹­:'):
                    result['is_perfect_match'] = 'ì˜ˆ' in line
                elif line.startswith('ì‹ ë¢°ë„:'):
                    try:
                        confidence = int(''.join(filter(str.isdigit, line)))
                        result['confidence'] = confidence
                    except:
                        pass
                elif line.startswith('ê²€ì¦ëœíŒ©ìŠ¤:'):
                    result['verified_fax'] = line.replace('ê²€ì¦ëœíŒ©ìŠ¤:', '').strip()
                elif line.startswith('ê²€ì¦ëœê¸°ê´€:'):
                    result['verified_institution'] = line.replace('ê²€ì¦ëœê¸°ê´€:', '').strip()
                elif line.startswith('ì‚¬ìœ :'):
                    result['reason'] = line.replace('ì‚¬ìœ :', '').strip()
            
            return result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI ì™„ë²½ ë§¤ì¹­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'is_perfect_match': False,
                'confidence': 0,
                'verified_fax': original_fax,
                'verified_institution': ai_institution,
                'reason': f'ë¶„ì„ ì˜¤ë¥˜: {e}'
            }
    
    def _optimize_batch_processing(self):
        """SystemAnalyzer ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""
        try:
            # í˜„ì¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
            resources = self.system_analyzer.get_current_resources()
            
            if resources:
                memory_usage = resources.get('memory_percent', 0)
                cpu_usage = resources.get('cpu_percent', 0)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ì¡°ì •
                recommended_batch = self.system_analyzer.get_recommended_batch_size()
                if recommended_batch != self.batch_size:
                    old_size = self.batch_size
                    self.batch_size = recommended_batch
                    self.logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸° ì¡°ì •: {old_size} â†’ {self.batch_size}")
                
                # ë¦¬ì†ŒìŠ¤ ìƒíƒœ ë¡œê·¸
                self.logger.debug(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: CPU {cpu_usage:.1f}%, ë©”ëª¨ë¦¬ {memory_usage:.1f}%")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°°ì¹˜ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _handle_system_overload(self):
        """ì‹œìŠ¤í…œ ê³¼ë¶€í•˜ ì²˜ë¦¬"""
        try:
            # í˜„ì¬ ì›Œì»¤ ìˆ˜ ê°ì†Œ
            current_workers = self.system_analyzer.current_workers
            if current_workers > 1:
                self.system_analyzer.adjust_workers('decrease')
                self.logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ ê³¼ë¶€í•˜ë¡œ ì›Œì»¤ ê°ì†Œ: {current_workers} â†’ {self.system_analyzer.current_workers}")
            
            # ë¶ˆí•„ìš”í•œ ë“œë¼ì´ë²„ ì •ë¦¬
            self._cleanup_idle_drivers()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
        except Exception as e:
            self.logger.error(f"âŒ ê³¼ë¶€í•˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _cleanup_idle_drivers(self):
        """Valid3.py ë°©ì‹: ìœ íœ´ ë“œë¼ì´ë²„ ì •ë¦¬ (ì—„ê²©íˆ 4ê°œ ì œí•œ)"""
        try:
            # 4ê°œ ì´ˆê³¼ ì‹œì—ë§Œ ì •ë¦¬
            current_manager_count = len(self.web_driver_managers)
            
            if current_manager_count > 4:
                # 4ê°œë¥¼ ì´ˆê³¼í•˜ëŠ” ë§¤ë‹ˆì €ë“¤ ì •ë¦¬ (ë†’ì€ ë²ˆí˜¸ë¶€í„°)
                workers_to_remove = sorted(self.web_driver_managers.keys(), reverse=True)[:current_manager_count - 4]
                
                for worker_id in workers_to_remove:
                    self.cleanup_worker_driver(worker_id)
                    
            self.logger.info(f"ğŸ§¹ ë“œë¼ì´ë²„ ì •ë¦¬ ì™„ë£Œ: {current_manager_count} -> {len(self.web_driver_managers)} (ìµœëŒ€ 4ê°œ ìœ ì§€)")
                            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìœ íœ´ ë“œë¼ì´ë²„ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def cleanup_worker_driver(self, worker_id: int):
        """Valid3.py ë°©ì‹: ì›Œì»¤ë³„ ë“œë¼ì´ë²„ ì™„ì „ ì •ë¦¬ (í¬íŠ¸ í•´ì œ í¬í•¨)"""
        try:
            with self.driver_lock:
                limited_worker_id = worker_id % 4  # 0~3ìœ¼ë¡œ ì œí•œ
                
                if limited_worker_id in self.web_driver_managers:
                    web_manager = self.web_driver_managers[limited_worker_id]
                    
                    # ì›Œì»¤ê°€ ì‚¬ìš©ì¤‘ì¸ í¬íŠ¸ í•´ì œ
                    if limited_worker_id in self.port_manager.port_assignments:
                        assigned_port = self.port_manager.port_assignments[limited_worker_id]
                        self.port_manager.release_port(assigned_port, limited_worker_id)
                        self.logger.debug(f"ğŸ”“ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}) í¬íŠ¸ {assigned_port} í•´ì œ")
                    
                    # ë“œë¼ì´ë²„ ì°¸ì¡° ì œê±° (ë¬´í•œì¦ì‹ ë°©ì§€)
                    if hasattr(web_manager, 'driver'):
                        web_manager.driver = None
                    
                    # WebDriverManagerì˜ ì •ë¦¬ ë©”ì„œë“œ í˜¸ì¶œ
                    if hasattr(web_manager, 'cleanup_all_drivers'):
                        web_manager.cleanup_all_drivers()
                    elif hasattr(web_manager, 'cleanup'):
                        web_manager.cleanup()
                    
                    # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
                    del self.web_driver_managers[limited_worker_id]
                    self.logger.debug(f"ğŸ§¹ ì›Œì»¤ {worker_id} (ì œí•œ:{limited_worker_id}) WebDriverManager ì™„ì „ ì •ë¦¬ (í¬íŠ¸ í•´ì œ í¬í•¨)")
        except Exception as e:
            self.logger.debug(f"âš ï¸ ì›Œì»¤ {worker_id} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
    
    def force_kill_all_chrome_processes(self):
        """Valid3.py ë°©ì‹: í¬ë¡¬ í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ (ë¹„ìƒìš©)"""
        try:
            import subprocess
            import platform
            
            if platform.system() == "Windows":
                # Windowsì—ì„œ Chrome í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
                try:
                    subprocess.run(['taskkill', '/f', '/im', 'chrome.exe'], 
                                 capture_output=True, text=True, timeout=10)
                    subprocess.run(['taskkill', '/f', '/im', 'chromedriver.exe'], 
                                 capture_output=True, text=True, timeout=10)
                    self.logger.info("ğŸ”¨ Windows Chrome í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Windows Chrome ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            else:
                # Linux/Macì—ì„œ Chrome í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
                try:
                    subprocess.run(['pkill', '-f', 'chrome'], 
                                 capture_output=True, text=True, timeout=10)
                    subprocess.run(['pkill', '-f', 'chromedriver'], 
                                 capture_output=True, text=True, timeout=10)
                    self.logger.info("ğŸ”¨ Unix Chrome í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Unix Chrome ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            self.logger.error(f"âŒ Chrome í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
    
    def cleanup_all_drivers(self):
        """Valid3.py ë°©ì‹: ëª¨ë“  ë“œë¼ì´ë²„ ì™„ì „ ì •ë¦¬ (í¬íŠ¸ ê´€ë¦¬ í¬í•¨)"""
        try:
            self.logger.info(f"ğŸ§¹ ì „ì²´ ë“œë¼ì´ë²„ ì •ë¦¬ ì‹œì‘: {len(self.web_driver_managers)}ê°œ")
            
            # ëª¨ë“  ì›Œì»¤ì˜ WebDriverManager ì •ë¦¬
            worker_ids = list(self.web_driver_managers.keys())
            for worker_id in worker_ids:
                self.cleanup_worker_driver(worker_id)
            
            # ë“œë¼ì´ë²„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
            self.web_driver_managers.clear()
            
            # ëª¨ë“  í¬íŠ¸ í•´ì œ
            self.port_manager.release_all_ports()
            
            # ê°•ì œ Chrome í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ (ë¹„ìƒìš©)
            self.force_kill_all_chrome_processes()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.logger.info("ğŸ§¹ ì „ì²´ ë“œë¼ì´ë²„ ì •ë¦¬ ì™„ë£Œ (í¬íŠ¸ í•´ì œ í¬í•¨)")
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ ë“œë¼ì´ë²„ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ì‹œìŠ¤í…œ ì „ì²´ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘")
            
            # ëª¨ë“  ë“œë¼ì´ë²„ ì •ë¦¬
            self.cleanup_all_drivers()
            
            # SystemAnalyzer ì •ë¦¬
            if hasattr(self, 'system_analyzer'):
                self.system_analyzer.cleanup()
            
            # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìµœì¢… ì •ë¦¬ (ì„ íƒì )
            try:
                self._cleanup_old_checkpoint_files("rawdatafile")
                self.logger.info("ğŸ—‘ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìµœì¢… ì •ë¦¬ ì™„ë£Œ")
            except:
                pass  # ì •ë¦¬ ì‹¤íŒ¨í•´ë„ í”„ë¡œê·¸ë¨ ì¢…ë£Œì—ëŠ” ì˜í–¥ ì—†ìŒ
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            self.logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            import gc
            gc.collect()
            
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸
            memory_mb = self.system_analyzer.get_memory_usage_mb()
            self.logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (í˜„ì¬: {memory_mb}MB)")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def process_batch_data(self, df: pd.DataFrame) -> List[CompValidationResult]:
        """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (100í–‰ì”©)"""
        all_results = []
        total_rows = len(df)
        
        for batch_start in range(0, total_rows, self.batch_size):
            batch_end = min(batch_start + self.batch_size, total_rows)
            batch_df = df.iloc[batch_start:batch_end]
            
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬: {batch_start+1}~{batch_end}/{total_rows}")
            
            # ì—„ê²©íˆ 4ê°œë¡œ ì œí•œëœ ì›Œì»¤ ì‚¬ìš©
            optimal_workers = 4
            
            # ë³‘ë ¬ ì²˜ë¦¬
            batch_results = []
            with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                future_to_row = {
                    executor.submit(
                        self.process_validation_pipeline, 
                        row, 
                        batch_start + idx, 
                        idx % optimal_workers
                    ): (batch_start + idx, row)
                    for idx, (_, row) in enumerate(batch_df.iterrows())
                }
                
                for future in as_completed(future_to_row):
                    row_index, row_data = future_to_row[future]
                    try:
                        result = future.result()
                        batch_results.append(result)
                    except Exception as e:
                        self.logger.error(f"âŒ í–‰ {row_index} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        # ì‹¤íŒ¨í•œ í–‰ì— ëŒ€í•œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±
                        failed_result = CompValidationResult(
                            row_index=row_index,
                            region=row_data.get('region', ''),
                            district=row_data.get('district', ''),
                            institution_name=row_data.get('institution_name', ''),
                            address=row_data.get('address', ''),
                            phone=row_data.get('phone', ''),
                            fax=row_data.get('fax', ''),
                            error_message=str(e)
                        )
                        batch_results.append(failed_result)
            
            all_results.extend(batch_results)
            self.processed_count += len(batch_results)
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (JSON ì²´í¬í¬ì¸íŠ¸)
            self._save_checkpoint(batch_results, batch_start)
            
            # SystemAnalyzer ê¸°ë°˜ ë™ì  ìµœì í™”
            self._optimize_batch_processing()
            
            # ë°°ì¹˜ ì™„ë£Œ ë¡œê·¸
            success_count = sum(1 for r in batch_results if r.success)
            self.logger.info(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {success_count}/{len(batch_results)} ì„±ê³µ")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬ ë° ì¡°ì •
            if not self.system_analyzer.is_system_healthy():
                self.logger.warning("âš ï¸ ì‹œìŠ¤í…œ ê³¼ë¶€í•˜ ê°ì§€, ì›Œì»¤ ì¡°ì • ë° ëŒ€ê¸°...")
                self._handle_system_overload()
                time.sleep(10)
            else:
                # ê±´ê°•í•œ ìƒíƒœë©´ ì ì‹œ ì‰¬ê³  ë‹¤ìŒ ë°°ì¹˜
                time.sleep(2)
        
        return all_results
    
    def _save_checkpoint(self, batch_results: List[CompValidationResult], batch_start: int):
        """ì¤‘ê°„ ê²°ê³¼ JSON ì €ì¥ (ìµœì‹  1ê°œë§Œ ìœ ì§€, ì´ì „ íŒŒì¼ ìë™ ì‚­ì œ)"""
        try:
            # rawdatafile ë””ë ‰í† ë¦¬ í™•ì¸
            checkpoint_dir = "rawdatafile"
            if not os.path.exists(checkpoint_dir):
                os.makedirs(checkpoint_dir)
            
            # ì´ì „ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì‚­ì œ
            self._cleanup_old_checkpoint_files(checkpoint_dir)
            
            # ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° êµ¬ì„±
            checkpoint_data = {
                'batch_info': {
                    'batch_start': batch_start,
                    'batch_size': len(batch_results),
                    'timestamp': datetime.now().isoformat(),
                    'total_processed': self.processed_count
                },
                'system_status': {
                    'current_workers': 4,  # ê³ ì •ê°’
                    'memory_usage': self.system_analyzer.get_memory_usage_mb(),
                    'is_healthy': self.system_analyzer.is_system_healthy(),
                    'active_drivers': len(self.web_driver_managers),
                    'port_status': self.port_manager.get_port_status()
                },
                'results': []
            }
            
            # ê°œë³„ ê²°ê³¼ ë°ì´í„°
            for result in batch_results:
                result_data = {
                    'row_index': result.row_index,
                    'region': result.region,
                    'district': result.district,
                    'institution_name': result.institution_name,
                    'address': result.address,
                    'phone': result.phone,
                    'fax': result.fax,
                    'phone_real_institution': result.phone_real_institution,
                    'phone_verified': result.phone_verified,
                    'fax_real_institution': result.fax_real_institution,
                    'fax_verified': result.fax_verified,
                    'validation_1st': result.validation_1st,
                    'validation_2nd': result.validation_2nd,
                    'validation_3rd': result.validation_3rd,
                    'validation_4th': result.validation_4th,
                    'validation_5th': result.validation_5th,
                    'validation_6th': result.validation_6th,
                    'extracted_links': result.extracted_links,
                    'ai_responses': result.ai_responses,
                    'processing_time': result.processing_time,
                    'error_message': result.error_message,
                    'success': result.success
                }
                checkpoint_data['results'].append(result_data)
            
            # ìƒˆë¡œìš´ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì €ì¥ (ìµœì‹  1ê°œë§Œ)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            checkpoint_path = f"{checkpoint_dir}/checkpoint_latest_{timestamp}.json"
            
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
            
            # ë°°ì¹˜ ì„±ê³µë¥  ë¡œê·¸
            success_count = sum(1 for r in batch_results if r.success)
            success_rate = (success_count / len(batch_results) * 100) if batch_results else 0
            
            self.logger.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ìµœì‹  1ê°œë§Œ ìœ ì§€): {os.path.basename(checkpoint_path)}")
            self.logger.info(f"ğŸ“Š ë°°ì¹˜ ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{len(batch_results)})")
            
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _cleanup_old_checkpoint_files(self, checkpoint_dir: str):
        """ì´ì „ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì‚­ì œ"""
        try:
            import glob
            
            # checkpoint_*.json íŒ¨í„´ì˜ ëª¨ë“  íŒŒì¼ ì°¾ê¸°
            old_checkpoint_files = glob.glob(f"{checkpoint_dir}/checkpoint_*.json")
            
            # ì´ì „ íŒŒì¼ë“¤ ì‚­ì œ
            deleted_count = 0
            for file_path in old_checkpoint_files:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    self.logger.debug(f"ğŸ—‘ï¸ ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(file_path)}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}")
            
            if deleted_count > 0:
                self.logger.info(f"ğŸ—‘ï¸ ì´ì „ ì²´í¬í¬ì¸íŠ¸ {deleted_count}ê°œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def save_final_csv(self, results: List[CompValidationResult], original_df: pd.DataFrame) -> str:
        """ìµœì¢… CSV ì €ì¥"""
        try:
            # rawdatafile ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
            output_dir = "rawdatafile"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                self.logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
            
            # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
            output_df = original_df.copy()
            
            # G/H/J/K ì»¬ëŸ¼ ì¶”ê°€ (ì „í™”/íŒ©ìŠ¤ ì‹¤ì œê¸°ê´€, ì˜¬ë°”ë¥¸ ë²ˆí˜¸)
            output_df['G_ì „í™”ì‹¤ì œê¸°ê´€'] = ""
            output_df['H_ì˜¬ë°”ë¥¸ì „í™”ë²ˆí˜¸'] = ""
            output_df['J_íŒ©ìŠ¤ì‹¤ì œê¸°ê´€'] = ""
            output_df['K_ì˜¬ë°”ë¥¸íŒ©ìŠ¤ë²ˆí˜¸'] = ""
            
            # N~S ì»¬ëŸ¼: 1~6ì°¨ ê²€ì¦ê°’ë“¤
            validation_columns = [
                'N_1ì°¨ê²€ì¦ê°’_ì§€ì—­ë§¤ì¹­',
                'O_2ì°¨ê²€ì¦ê°’_êµ¬ê¸€ê²€ìƒ‰', 
                'P_3ì°¨ê²€ì¦ê°’_ë§í¬ìˆ˜ì§‘',
                'Q_4ì°¨ê²€ì¦ê°’_ë³‘ë ¬í¬ë¡¤ë§',
                'R_5ì°¨ê²€ì¦ê°’_AIë¶„ì„',
                'S_6ì°¨ê²€ì¦ê°’_ì¢…í•©ë§¤ì¹­'
            ]
            
            for col in validation_columns:
                output_df[col] = ""
            
            # T~X ì»¬ëŸ¼: ì¶”ì¶œë§í¬ 1~5
            link_columns = []
            for i in range(5):
                col_name = f'{chr(84+i)}_ì¶”ì¶œë§í¬{i+1}'
                link_columns.append(col_name)
                output_df[col_name] = ""
            
            # Y~AC ì»¬ëŸ¼: ë§í¬ë³„ AIì‘ë‹µ 1~5
            ai_response_columns = []
            for i in range(5):
                col_name = f'{chr(89+i)}_ë§í¬{i+1}_AIì‘ë‹µ'
                ai_response_columns.append(col_name)
                output_df[col_name] = ""
            
            # ê²°ê³¼ ë°ì´í„° ì±„ìš°ê¸°
            results_dict = {r.row_index: r for r in results}
            
            for idx in range(len(output_df)):
                if idx in results_dict:
                    result = results_dict[idx]
                    
                    # G/H/J/K ì»¬ëŸ¼ ì±„ìš°ê¸°
                    output_df.at[idx, 'G_ì „í™”ì‹¤ì œê¸°ê´€'] = result.phone_real_institution
                    output_df.at[idx, 'H_ì˜¬ë°”ë¥¸ì „í™”ë²ˆí˜¸'] = result.phone_verified
                    output_df.at[idx, 'J_íŒ©ìŠ¤ì‹¤ì œê¸°ê´€'] = result.fax_real_institution
                    output_df.at[idx, 'K_ì˜¬ë°”ë¥¸íŒ©ìŠ¤ë²ˆí˜¸'] = result.fax_verified
                    
                    # N~S ì»¬ëŸ¼ ì±„ìš°ê¸° (ê²€ì¦ê°’ë“¤)
                    validation_values = [
                        result.validation_1st,
                        result.validation_2nd,
                        result.validation_3rd,
                        result.validation_4th,
                        result.validation_5th,
                        result.validation_6th
                    ]
                    
                    for i, (col, value) in enumerate(zip(validation_columns, validation_values)):
                        output_df.at[idx, col] = value
                    
                    # T~X ì»¬ëŸ¼ ì±„ìš°ê¸° (ë§í¬ë“¤)
                    for i, link in enumerate(result.extracted_links[:5]):
                        if i < len(link_columns):
                            output_df.at[idx, link_columns[i]] = link
                    
                    # Y~AC ì»¬ëŸ¼ ì±„ìš°ê¸° (AI ì‘ë‹µë“¤)
                    for i, response in enumerate(result.ai_responses[:5]):
                        if i < len(ai_response_columns):
                            output_df.at[idx, ai_response_columns[i]] = response
            
            # ìµœì¢… CSV ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f"{output_dir}/comp_result_{timestamp}.csv"
            
            # CSV ì €ì¥ (UTF-8 BOMìœ¼ë¡œ í•œê¸€ í˜¸í™˜ì„± í™•ë³´)
            output_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ì •ë³´ ì¶”ê°€
            total_rows = len(output_df)
            processed_rows = len(results)
            success_rows = sum(1 for r in results if r.success)
            
            self.logger.info(f"ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
            self.logger.info(f"   ğŸ“ íŒŒì¼: {output_path}")
            self.logger.info(f"   ğŸ“Š í†µê³„: ì „ì²´ {total_rows}í–‰, ì²˜ë¦¬ {processed_rows}í–‰, ì„±ê³µ {success_rows}í–‰")
            
            return output_path
            
        except Exception as e:
            self.logger.error(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    

    
    def run(self, csv_file_path: str):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        start_time = time.time()
        
        try:
            self.logger.info("ğŸš€ CompCrawlingSystem ì‹¤í–‰ ì‹œì‘")
            self.logger.info(f"ğŸ“ ì…ë ¥ íŒŒì¼: {csv_file_path}")
            
            # 0. ì‹œì‘ ì‹œ ì´ì „ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì •ë¦¬
            self._cleanup_old_checkpoint_files("rawdatafile")
            
            # 1. CSV ë¡œë“œ ë° ê²€ì¦
            if not os.path.exists(csv_file_path):
                raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file_path}")
            
            df = self.load_csv_data(csv_file_path)
            self.logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(df)}í–‰")
            
            # 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            if not self.system_analyzer.is_system_healthy():
                self.logger.warning("âš ï¸ ì‹œìŠ¤í…œ ìƒíƒœê°€ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                # ì—¬ê¸°ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ê±°ë‚˜ ìë™ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆìŒ
            
            # 3. ë°°ì¹˜ ì²˜ë¦¬ (ì§„í–‰ë¥  í‘œì‹œ)
            self.logger.info(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {self.batch_size})")
            results = self.process_batch_data(df)
            
            # 4. ê²°ê³¼ ì €ì¥
            output_path = self.save_final_csv(results, df)
            
            # 5. ìµœì¢… í†µê³„ ì¶œë ¥
            end_time = time.time()
            total_time = end_time - start_time
            
            success_count = sum(1 for r in results if r.success)
            success_rate = (success_count / len(results) * 100) if results else 0
            
            self.logger.info("=" * 60)
            self.logger.info("ğŸ‰ CompCrawlingSystem ì‹¤í–‰ ì™„ë£Œ")
            self.logger.info(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
            self.logger.info(f"   - ì „ì²´ í–‰ìˆ˜: {len(df):,}í–‰")
            self.logger.info(f"   - ì²˜ë¦¬ ì™„ë£Œ: {len(results):,}í–‰")
            self.logger.info(f"   - ì„±ê³µë¥ : {success_rate:.1f}% ({success_count:,}/{len(results):,})")
            self.logger.info(f"   - ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
            self.logger.info(f"   - í‰ê·  ì²˜ë¦¬ì†ë„: {len(results)/total_time:.1f}í–‰/ì´ˆ")
            self.logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")
            self.logger.info("=" * 60)
            
            return output_path
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            raise
        finally:
            self.cleanup()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # CSV íŒŒì¼ ê²½ë¡œ (ì ˆëŒ€ê²½ë¡œì™€ ìƒëŒ€ê²½ë¡œ ëª¨ë‘ ì§€ì›)
    csv_file_path = r"rawdatafile\failed_data_250809.csv"
    
    # ì ˆëŒ€ê²½ë¡œ ëŒ€ì•ˆ (íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‹œë„)
    if not os.path.exists(csv_file_path):
        alternative_path = r"C:\Users\MyoengHo Shin\pjt\info_crawl\rawdatafile\failed_data_250809.csv"
        if os.path.exists(alternative_path):
            csv_file_path = alternative_path
        else:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            print(f"   1. {os.path.abspath('rawdatafile/failed_data_250809.csv')}")
            print(f"   2. {alternative_path}")
            return
    
    print("ğŸš€ CompCrawlingSystem ì‹œì‘")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {csv_file_path}")
    print("ğŸ”§ í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í† ê¸€: 'h' í‚¤ (keyboard ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹œ)")
    print("â¸ï¸ ì¤‘ë‹¨: Ctrl+C")
    print("=" * 60)
    
    system = None
    
    try:
        system = CompCrawlingSystem()
        output_path = system.run(csv_file_path)
        print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")
        
    except KeyboardInterrupt:
        print("\nâ¸ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        if system:
            print("ğŸ§¹ ì •ë¦¬ ì‘ì—… ì¤‘...")
            
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ“‹ ìì„¸í•œ ì˜¤ë¥˜ ë‚´ìš©ì€ logs/ í´ë”ì˜ ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    finally:
        if system:
            try:
                system.cleanup()
            except:
                pass
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")


if __name__ == "__main__":
    main()
