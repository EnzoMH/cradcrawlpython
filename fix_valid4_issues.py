#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Valid4 ë¬¸ì œ í•´ê²° ìŠ¤í¬ë¦½íŠ¸
mappingdata250809.csvì˜ ë§¤ì¹­ ì‹¤íŒ¨ ë°ì´í„°ë¥¼ ì¬ì²˜ë¦¬í•˜ëŠ” ê°œì„ ëœ ë¡œì§
"""

import pandas as pd
import logging
import time
from typing import Dict, List, Tuple
import traceback

class Valid4IssueResolver:
    """Valid4 ë¬¸ì œ í•´ê²° ê´€ë¦¬ì"""
    
    def __init__(self):
        self.logger = self._setup_logger()
        self.failed_data = None
        self.need_web_search_data = None
        
    def _setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("Valid4IssueResolver")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def analyze_csv_issues(self, csv_path: str = "mappingdata250809.csv") -> Dict:
        """CSV íŒŒì¼ì˜ ë¬¸ì œì  ë¶„ì„"""
        try:
            self.logger.info(f"ğŸ“Š CSV íŒŒì¼ ë¶„ì„ ì‹œì‘: {csv_path}")
            
            # CSV ë¡œë“œ (ì¸ì½”ë”© ìë™ ê°ì§€)
            encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_path, encoding=encoding)
                    self.logger.info(f"âœ… CSV ë¡œë“œ ì„±ê³µ: {encoding} ì¸ì½”ë”©")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                raise Exception("ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨")
            total_rows = len(df)
            
            # ë¬¸ì œ ìƒí™© ë¶„ì„
            analysis = {
                'total_rows': total_rows,
                'matching_failures': 0,
                'web_search_needed': 0,
                'phase0_complete': 0,
                'zero_confidence': 0,
                'partial_matches': 0
            }
            
            # ë§¤ì¹­ ì‹¤íŒ¨ ê³„ì‚°
            phone_failures = df['ì „í™”_ë§¤ì¹­_ìœ í˜•'].str.contains('ë§¤ì¹­ì‹¤íŒ¨', na=False).sum()
            fax_failures = df['íŒ©ìŠ¤_ë§¤ì¹­_ìœ í˜•'].str.contains('ë§¤ì¹­ì‹¤íŒ¨', na=False).sum()
            analysis['matching_failures'] = phone_failures + fax_failures
            
            # ì›¹ ê²€ìƒ‰ í•„ìš”í•œ ë°ì´í„°
            analysis['web_search_needed'] = df['ìµœì¢…_ê²°ê³¼'].str.contains('ì›¹ ê²€ìƒ‰ ì™„ë£Œ - ì¶”ê°€ ê²€ì¦ í•„ìš”', na=False).sum()
            
            # Phase 0 ì™„ë£Œ ë°ì´í„°
            analysis['phase0_complete'] = df['ìµœì¢…_ê²°ê³¼'].str.contains('Phase 0 ìë™ ë¼ë²¨ë§ ì™„ë£Œ', na=False).sum()
            
            # ì‹ ë¢°ë„ 0ì¸ ë°ì´í„°
            analysis['zero_confidence'] = df['Phase0_ì‹ ë¢°ë„'].eq(0).sum()
            
            # ë¶€ë¶„ ë§¤ì¹­ (ì „í™” ë˜ëŠ” íŒ©ìŠ¤ ì¤‘ í•˜ë‚˜ë§Œ ì„±ê³µ)
            phone_success = df['Phase0_ì „í™”ë§¤ì¹­'].eq(True)
            fax_success = df['Phase0_íŒ©ìŠ¤ë§¤ì¹­'].eq(True)
            analysis['partial_matches'] = ((phone_success & ~fax_success) | (~phone_success & fax_success)).sum()
            
            self.logger.info("ğŸ“ˆ ë¶„ì„ ê²°ê³¼:")
            self.logger.info(f"   - ì „ì²´ ë ˆì½”ë“œ: {analysis['total_rows']:,}ê°œ")
            self.logger.info(f"   - ë§¤ì¹­ ì‹¤íŒ¨: {analysis['matching_failures']:,}ê±´")
            self.logger.info(f"   - ì›¹ ê²€ìƒ‰ í•„ìš”: {analysis['web_search_needed']:,}ê±´")
            self.logger.info(f"   - Phase 0 ì™„ë£Œ: {analysis['phase0_complete']:,}ê±´")
            self.logger.info(f"   - ì‹ ë¢°ë„ 0: {analysis['zero_confidence']:,}ê±´")
            self.logger.info(f"   - ë¶€ë¶„ ë§¤ì¹­: {analysis['partial_matches']:,}ê±´")
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"âŒ CSV ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def extract_failed_records(self, csv_path: str = "mappingdata250809.csv") -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ì‹¤íŒ¨í•œ ë ˆì½”ë“œë“¤ì„ ì¶”ì¶œ"""
        try:
            # CSV ë¡œë“œ (ì¸ì½”ë”© ìë™ ê°ì§€)
            encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_path, encoding=encoding)
                    self.logger.info(f"âœ… CSV ë¡œë“œ ì„±ê³µ: {encoding} ì¸ì½”ë”©")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                raise Exception("ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨")
            
            # ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ (ì „í™”ë‚˜ íŒ©ìŠ¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨)
            failed_mask = (
                df['ì „í™”_ë§¤ì¹­_ìœ í˜•'].str.contains('ë§¤ì¹­ì‹¤íŒ¨', na=False) |
                df['íŒ©ìŠ¤_ë§¤ì¹­_ìœ í˜•'].str.contains('ë§¤ì¹­ì‹¤íŒ¨', na=False) |
                df['Phase0_ì‹ ë¢°ë„'].eq(0)
            )
            self.failed_data = df[failed_mask].copy()
            
            # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ë ˆì½”ë“œ
            web_search_mask = df['ìµœì¢…_ê²°ê³¼'].str.contains('ì›¹ ê²€ìƒ‰ ì™„ë£Œ - ì¶”ê°€ ê²€ì¦ í•„ìš”', na=False)
            self.need_web_search_data = df[web_search_mask].copy()
            
            self.logger.info(f"ğŸ” ì¶”ì¶œ ì™„ë£Œ:")
            self.logger.info(f"   - ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ: {len(self.failed_data)}ê°œ")
            self.logger.info(f"   - ì›¹ ê²€ìƒ‰ í•„ìš” ë ˆì½”ë“œ: {len(self.need_web_search_data)}ê°œ")
            
            return self.failed_data, self.need_web_search_data
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤íŒ¨ ë ˆì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame(), pd.DataFrame()
    
    def generate_reprocessing_recommendations(self) -> List[str]:
        """ì¬ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = [
            "ğŸ”§ Valid4.py ê°œì„  ê¶Œì¥ì‚¬í•­:",
            "",
            "1. Phase 0 ìë™ ë¼ë²¨ë§ ê°•í™”:",
            "   - ì„¼í„° ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ (ìµœì‹  ì „í™”/íŒ©ìŠ¤ ì •ë³´)",
            "   - ìœ ì‚¬ ë¬¸ìì—´ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ë„ì… (fuzzy matching)",
            "   - ì§€ì—­ ê¸°ë°˜ ë§¤ì¹­ ë¡œì§ ê°•í™”",
            "",
            "2. ì›¹ ê²€ìƒ‰ ë¡œì§ ê°œì„ :",
            "   - ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ í™œìš© (Google + Naver + Daum)",
            "   - ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ì–‘í™” (ê¸°ê´€ëª… + ì§€ì—­ + ì „í™”ë²ˆí˜¸ ì¡°í•©)",
            "   - AI ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ê°•í™”",
            "",
            "3. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜:",
            "   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„",
            "   - ë¶€ë¶„ ë§¤ì¹­ ì‹œ ì¶”ê°€ ê²€ì¦ ë¡œì§",
            "   - ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ê²€ìƒ‰ ì „ëµ",
            "",
            "4. ì„±ëŠ¥ ìµœì í™”:",
            "   - ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° ì¡°ì •",
            "   - ë™ì‹œ ì‘ì—…ì ìˆ˜ ìµœì í™”",
            "   - ìºì‹± ë©”ì»¤ë‹ˆì¦˜ ë„ì…",
            "",
            "5. ë°ì´í„° í’ˆì§ˆ ê°œì„ :",
            "   - ì…ë ¥ ë°ì´í„° ì •ê·œí™”",
            "   - ì¤‘ë³µ ì œê±° ë¡œì§",
            "   - ë°ì´í„° ê²€ì¦ ê°•í™”"
        ]
        
        return recommendations
    
    def save_analysis_report(self, analysis: Dict, recommendations: List[str]) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥"""
        try:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            report_file = f"valid4_analysis_report_{timestamp}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("Valid4 ì‹œìŠ¤í…œ ë¶„ì„ ë¦¬í¬íŠ¸\n")
                f.write("=" * 60 + "\n")
                f.write(f"ìƒì„± ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼:\n")
                f.write("-" * 30 + "\n")
                for key, value in analysis.items():
                    f.write(f"{key}: {value:,}\n")
                
                f.write("\nğŸ“ˆ ì„±ê³µë¥  ê³„ì‚°:\n")
                f.write("-" * 30 + "\n")
                if analysis.get('total_rows', 0) > 0:
                    success_rate = (analysis.get('phase0_complete', 0) / analysis['total_rows']) * 100
                    failure_rate = (analysis.get('matching_failures', 0) / (analysis['total_rows'] * 2)) * 100  # ì „í™”+íŒ©ìŠ¤
                    f.write(f"Phase 0 ì„±ê³µë¥ : {success_rate:.1f}%\n")
                    f.write(f"ë§¤ì¹­ ì‹¤íŒ¨ìœ¨: {failure_rate:.1f}%\n")
                
                f.write("\n" + "\n".join(recommendations) + "\n")
                
                f.write("\n" + "=" * 60 + "\n")
                f.write("ë¦¬í¬íŠ¸ ë\n")
                f.write("=" * 60 + "\n")
            
            self.logger.info(f"ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
            return report_file
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ”§ Valid4 ë¬¸ì œ í•´ê²° ë„êµ¬")
    print("=" * 60)
    
    resolver = Valid4IssueResolver()
    
    try:
        # 1. CSV ë¶„ì„
        print("\nğŸ“Š 1ë‹¨ê³„: CSV ë°ì´í„° ë¶„ì„")
        analysis = resolver.analyze_csv_issues()
        
        if not analysis:
            print("âŒ ë¶„ì„ ì‹¤íŒ¨")
            return
        
        # 2. ì‹¤íŒ¨ ë ˆì½”ë“œ ì¶”ì¶œ
        print("\nğŸ” 2ë‹¨ê³„: ì‹¤íŒ¨ ë ˆì½”ë“œ ì¶”ì¶œ")
        failed_data, web_search_data = resolver.extract_failed_records()
        
        # 3. ê¶Œì¥ì‚¬í•­ ìƒì„±
        print("\nğŸ’¡ 3ë‹¨ê³„: ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±")
        recommendations = resolver.generate_reprocessing_recommendations()
        
        # 4. ë¦¬í¬íŠ¸ ì €ì¥
        print("\nğŸ“‹ 4ë‹¨ê³„: ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥")
        report_file = resolver.save_analysis_report(analysis, recommendations)
        
        # 5. ìš”ì•½ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ¯ ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„")
        print("=" * 60)
        print(f"ğŸ“ˆ ë¶„ì„ ì™„ë£Œ: ì´ {analysis.get('total_rows', 0):,}ê°œ ë ˆì½”ë“œ")
        print(f"âŒ ì²˜ë¦¬ í•„ìš”: {len(failed_data):,}ê°œ ì‹¤íŒ¨ ë ˆì½”ë“œ")
        print(f"ğŸ” ì›¹ ê²€ìƒ‰ ëŒ€ê¸°: {len(web_search_data):,}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸: {report_file}")
        
        print("\nğŸ”§ ê¶Œì¥ ì¡°ì¹˜:")
        print("1. Valid4.pyì˜ CenterDataManager ì—…ë°ì´íŠ¸")
        print("2. Valid4WebSearchManagerì˜ ê²€ìƒ‰ ë¡œì§ ê°•í™”")
        print("3. ì‹¤íŒ¨ ë ˆì½”ë“œ ë°°ì¹˜ ì¬ì²˜ë¦¬ ì‹¤í–‰")
        print("4. ì›¹ ê²€ìƒ‰ ëŒ€ê¸° ë ˆì½”ë“œ ì¶”ê°€ ê²€ì¦")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print(traceback.format_exc())

if __name__ == "__main__":
    main()
