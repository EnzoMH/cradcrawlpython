#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ë° AI í—¤ë” ë¶„ì„ í´ë˜ìŠ¤
"""

import os
import pandas as pd
import logging
import google.generativeai as genai
from typing import Dict, List, Optional, Tuple
from datetime import datetime

class ExcelProcessor:
    """ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ë° AI í—¤ë” ë¶„ì„"""
    
    def __init__(self, logger=None):
        """
        ì—‘ì…€ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            logger: ë¡œê¹… ê°ì²´ (ê¸°ë³¸ê°’: None)
        """
        self.logger = logger or logging.getLogger(__name__)
        self.df = None
        self.original_headers = []
        self.mapped_headers = {}
        self.ai_model = None
        
        # í‘œì¤€ ì»¬ëŸ¼ ì •ì˜
        self.standard_columns = {
            'region': 'ì§€ì—­',
            'institution_name': 'ê¸°ê´€ëª…',
            'address': 'ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'fax': 'íŒ©ìŠ¤ë²ˆí˜¸',
            'homepage': 'í™ˆí˜ì´ì§€',
            'ai_phone': 'AIì¶”ì¶œì „í™”ë²ˆí˜¸',
            'ai_fax': 'AIì¶”ì¶œíŒ©ìŠ¤ë²ˆí˜¸'
        }
        
        self.logger.info("ğŸ“Š ì—‘ì…€ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def initialize_ai(self, api_key: str) -> bool:
        """
        Gemini AI ì´ˆê¸°í™”
        
        Args:
            api_key: Gemini API í‚¤
            
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            genai.configure(api_key=api_key)
            self.ai_model = genai.GenerativeModel('gemini-1.5-flash')
            self.logger.info("ğŸ¤– Gemini AI ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Gemini AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def load_excel_file(self, file_path: str) -> bool:
        """
        ì—‘ì…€ íŒŒì¼ ë¡œë“œ
        
        Args:
            file_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not os.path.exists(file_path):
                self.logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                return False
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext not in ['.xlsx', '.xls', '.csv']:
                self.logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
                return False
            
            self.logger.info(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì‹œì‘: {file_path}")
            
            # íŒŒì¼ ë¡œë“œ
            if file_ext == '.csv':
                self.df = pd.read_csv(file_path, encoding='utf-8-sig')
            else:
                self.df = pd.read_excel(file_path)
            
            self.logger.info(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰ Ã— {len(self.df.columns)}ì—´")
            
            # í—¤ë” ì •ë³´ ì €ì¥
            self.original_headers = list(self.df.columns)
            self.logger.info(f"ğŸ“‹ ì›ë³¸ í—¤ë”: {self.original_headers}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def detect_header_row(self) -> int:
        """
        í—¤ë” í–‰ ìë™ ê°ì§€
        
        Returns:
            int: í—¤ë” í–‰ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)
        """
        try:
            if self.df is None:
                return 0
            
            # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì¸ì§€ í™•ì¸
            first_row = self.df.iloc[0]
            
            # ë¬¸ìì—´ ë¹„ìœ¨ ê³„ì‚°
            string_count = sum(1 for val in first_row if isinstance(val, str))
            string_ratio = string_count / len(first_row)
            
            # ë¬¸ìì—´ ë¹„ìœ¨ì´ 70% ì´ìƒì´ë©´ í—¤ë”ë¡œ íŒë‹¨
            if string_ratio >= 0.7:
                self.logger.info("âœ… ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ê°ì§€")
                return 0
            
            # ìƒì„¸ ë¶„ì„ ìˆ˜í–‰
            self.logger.info("ğŸ” í—¤ë” í–‰ ìƒì„¸ ë¶„ì„ ì‹œì‘")
            return self._detailed_header_analysis()
            
        except Exception as e:
            self.logger.error(f"âŒ í—¤ë” í–‰ ê°ì§€ ì‹¤íŒ¨: {e}")
            return 0
    
    def _detailed_header_analysis(self) -> int:
        """í—¤ë” í–‰ ìƒì„¸ ë¶„ì„"""
        try:
            max_rows_to_check = min(10, len(self.df))
            best_header_row = 0
            best_score = 0
            
            for row_idx in range(max_rows_to_check):
                row = self.df.iloc[row_idx]
                score = self._calculate_header_score(row)
                
                if score > best_score:
                    best_score = score
                    best_header_row = row_idx
            
            self.logger.info(f"âœ… í—¤ë” í–‰ ê°ì§€ ì™„ë£Œ: {best_header_row + 1}ë²ˆì§¸ í–‰ (ì ìˆ˜: {best_score:.2f})")
            return best_header_row
            
        except Exception as e:
            self.logger.error(f"âŒ í—¤ë” í–‰ ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0
    
    def _calculate_header_score(self, row) -> float:
        """í—¤ë” ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0
            
            # ë¬¸ìì—´ ë¹„ìœ¨
            string_count = sum(1 for val in row if isinstance(val, str))
            score += (string_count / len(row)) * 40
            
            # ë¹ˆ ê°’ ë¹„ìœ¨ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
            empty_count = sum(1 for val in row if pd.isna(val) or val == '')
            score += (1 - empty_count / len(row)) * 30
            
            # í—¤ë” í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
            header_keywords = ['ì´ë¦„', 'ëª…ì¹­', 'ê¸°ê´€', 'ì£¼ì†Œ', 'ì „í™”', 'íŒ©ìŠ¤', 'í™ˆí˜ì´ì§€', 
                             'ì§€ì—­', 'êµ¬', 'ì‹œ', 'êµ°', 'name', 'address', 'phone', 'fax']
            
            keyword_count = 0
            for val in row:
                if isinstance(val, str):
                    for keyword in header_keywords:
                        if keyword in val.lower():
                            keyword_count += 1
                            break
            
            score += (keyword_count / len(row)) * 30
            
            return score
            
        except Exception as e:
            self.logger.error(f"âŒ í—¤ë” ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0
    
    def analyze_headers_with_ai(self) -> Dict:
        """
        AIë¥¼ ì‚¬ìš©í•œ í—¤ë” ë¶„ì„ ë° ë§¤í•‘ ì œì•ˆ
        
        Returns:
            Dict: í—¤ë” ë§¤í•‘ ê²°ê³¼
        """
        try:
            if not self.ai_model:
                self.logger.warning("âš ï¸ AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return self._fallback_header_mapping()
            
            self.logger.info("ğŸ¤– AI í—¤ë” ë¶„ì„ ì‹œì‘")
            
            # AI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._generate_header_analysis_prompt()
            
            # AI ë¶„ì„ ì‹¤í–‰
            response = self.ai_model.generate_content(prompt)
            
            # ì‘ë‹µ íŒŒì‹±
            mapping = self._parse_ai_response(response.text)
            
            if mapping:
                self.logger.info("âœ… AI í—¤ë” ë¶„ì„ ì™„ë£Œ")
                self._log_header_mapping(mapping)
                return mapping
            else:
                self.logger.warning("âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨, í´ë°± ë§¤í•‘ ì‚¬ìš©")
                return self._fallback_header_mapping()
            
        except Exception as e:
            self.logger.error(f"âŒ AI í—¤ë” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._fallback_header_mapping()
    
    def _generate_header_analysis_prompt(self) -> str:
        """AI í—¤ë” ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        headers_str = ", ".join(self.original_headers)
        
        prompt = f"""
ë‹¤ìŒ ì—‘ì…€ íŒŒì¼ì˜ í—¤ë”ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì»¬ëŸ¼ ë§¤í•‘ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

ì›ë³¸ í—¤ë”: {headers_str}

ë§¤í•‘í•  í‘œì¤€ ì»¬ëŸ¼:
- region: ì§€ì—­ ì •ë³´ (ì‹œ/êµ¬/êµ°)
- institution_name: ê¸°ê´€ëª… (í•™ì›, êµíšŒ, ì„¼í„° ë“±)
- address: ì£¼ì†Œ ì •ë³´ (ë„ë¡œëª…ì£¼ì†Œ, ì§€ë²ˆì£¼ì†Œ)
- phone: ì „í™”ë²ˆí˜¸
- fax: íŒ©ìŠ¤ë²ˆí˜¸
- homepage: í™ˆí˜ì´ì§€/ì›¹ì‚¬ì´íŠ¸

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "region": "ì›ë³¸í—¤ë”ëª…",
    "institution_name": "ì›ë³¸í—¤ë”ëª…",
    "address": "ì›ë³¸í—¤ë”ëª…",
    "phone": "ì›ë³¸í—¤ë”ëª…",
    "fax": "ì›ë³¸í—¤ë”ëª…",
    "homepage": "ì›ë³¸í—¤ë”ëª…"
}}

ë§¤í•‘í•  ìˆ˜ ì—†ëŠ” í•­ëª©ì€ nullë¡œ í‘œì‹œí•´ì£¼ì„¸ìš”.
"""
        return prompt
    
    def _parse_ai_response(self, response_text: str) -> Dict:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            import json
            import re
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if not json_match:
                return {}
            
            json_str = json_match.group(0)
            mapping = json.loads(json_str)
            
            # ìœ íš¨ì„± ê²€ì¦
            valid_mapping = {}
            for key, value in mapping.items():
                if key in self.standard_columns and value and value in self.original_headers:
                    valid_mapping[key] = value
            
            return valid_mapping
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
    
    def _fallback_header_mapping(self) -> Dict:
        """í´ë°± í—¤ë” ë§¤í•‘ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            mapping = {}
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘
            mapping_rules = {
                'region': ['ì§€ì—­', 'ì‹œ', 'êµ¬', 'êµ°', 'ìœ„ì¹˜', 'region', 'location'],
                'institution_name': ['ê¸°ê´€ëª…', 'ì´ë¦„', 'ëª…ì¹­', 'í•™ì›ëª…', 'êµíšŒëª…', 'name', 'institution'],
                'address': ['ì£¼ì†Œ', 'ì†Œì¬ì§€', 'address', 'addr'],
                'phone': ['ì „í™”ë²ˆí˜¸', 'ì „í™”', 'phone', 'tel'],
                'fax': ['íŒ©ìŠ¤ë²ˆí˜¸', 'íŒ©ìŠ¤', 'fax'],
                'homepage': ['í™ˆí˜ì´ì§€', 'ì›¹ì‚¬ì´íŠ¸', 'homepage', 'website', 'url']
            }
            
            for standard_col, keywords in mapping_rules.items():
                for header in self.original_headers:
                    header_lower = header.lower()
                    for keyword in keywords:
                        if keyword in header_lower:
                            mapping[standard_col] = header
                            break
                    if standard_col in mapping:
                        break
            
            self.logger.info("âœ… í´ë°± í—¤ë” ë§¤í•‘ ì™„ë£Œ")
            return mapping
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± í—¤ë” ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _log_header_mapping(self, mapping: Dict):
        """í—¤ë” ë§¤í•‘ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥"""
        try:
            self.logger.info("ğŸ“‹ í—¤ë” ë§¤í•‘ ê²°ê³¼:")
            for standard_col, original_header in mapping.items():
                standard_name = self.standard_columns.get(standard_col, standard_col)
                self.logger.info(f"   {standard_name} â† {original_header}")
            
            # ë§¤í•‘ë˜ì§€ ì•Šì€ í—¤ë”
            unmapped = [h for h in self.original_headers if h not in mapping.values()]
            if unmapped:
                self.logger.info(f"â“ ë§¤í•‘ë˜ì§€ ì•Šì€ í—¤ë”: {unmapped}")
                
        except Exception as e:
            self.logger.error(f"âŒ í—¤ë” ë§¤í•‘ ë¡œê·¸ ì¶œë ¥ ì‹¤íŒ¨: {e}")
    
    def manual_header_mapping(self) -> Dict:
        """ì‚¬ìš©ì ìˆ˜ë™ í—¤ë” ë§¤í•‘"""
        try:
            self.logger.info("âœ‹ ìˆ˜ë™ í—¤ë” ë§¤í•‘ ì‹œì‘")
            print("\n" + "="*60)
            print("ğŸ“‹ ìˆ˜ë™ í—¤ë” ë§¤í•‘")
            print("="*60)
            
            print(f"ì›ë³¸ í—¤ë”: {self.original_headers}")
            print("\ní‘œì¤€ ì»¬ëŸ¼:")
            for key, name in self.standard_columns.items():
                print(f"  {key}: {name}")
            
            mapping = {}
            
            for key, name in self.standard_columns.items():
                if key in ['ai_phone', 'ai_fax']:  # AI ê²°ê³¼ ì»¬ëŸ¼ì€ ë‚˜ì¤‘ì— ì¶”ê°€
                    continue
                    
                print(f"\n{name}ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ í—¤ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
                for i, header in enumerate(self.original_headers):
                    print(f"  {i+1}. {header}")
                print("  0. ì—†ìŒ")
                
                try:
                    choice = input("ì„ íƒ (ë²ˆí˜¸): ").strip()
                    if choice == '0':
                        continue
                    
                    index = int(choice) - 1
                    if 0 <= index < len(self.original_headers):
                        mapping[key] = self.original_headers[index]
                        print(f"âœ… {name} â† {self.original_headers[index]}")
                    else:
                        print("âŒ ì˜ëª»ëœ ì„ íƒ")
                        
                except ValueError:
                    print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
                    continue
            
            self.logger.info("âœ… ìˆ˜ë™ í—¤ë” ë§¤í•‘ ì™„ë£Œ")
            self._log_header_mapping(mapping)
            
            return mapping
            
        except Exception as e:
            self.logger.error(f"âŒ ìˆ˜ë™ í—¤ë” ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def apply_header_mapping(self, mapping: Dict) -> bool:
        """
        í—¤ë” ë§¤í•‘ ì ìš©
        
        Args:
            mapping: í—¤ë” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            bool: ì ìš© ì„±ê³µ ì—¬ë¶€
        """
        try:
            if self.df is None:
                self.logger.error("âŒ ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                return False
            
            # ë§¤í•‘ ì ìš©
            rename_dict = {}
            for standard_col, original_header in mapping.items():
                if original_header in self.df.columns:
                    rename_dict[original_header] = standard_col
            
            self.df = self.df.rename(columns=rename_dict)
            
            # ëˆ„ë½ëœ í‘œì¤€ ì»¬ëŸ¼ ì¶”ê°€
            for standard_col in self.standard_columns.keys():
                if standard_col not in self.df.columns:
                    self.df[standard_col] = ''
            
            # NaN ê°’ ì²˜ë¦¬
            self.df = self.df.fillna('')
            
            self.mapped_headers = mapping
            self.logger.info("âœ… í—¤ë” ë§¤í•‘ ì ìš© ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ í—¤ë” ë§¤í•‘ ì ìš© ì‹¤íŒ¨: {e}")
            return False
    
    def get_processed_data(self) -> pd.DataFrame:
        """
        ì²˜ë¦¬ëœ ë°ì´í„° ë°˜í™˜
        
        Returns:
            pd.DataFrame: ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        return self.df.copy() if self.df is not None else pd.DataFrame()
    
    def save_processed_data(self, output_path: str = None) -> str:
        """
        ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        
        Args:
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: None)
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            if self.df is None:
                raise ValueError("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            if not output_path:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
                output_path = os.path.join(desktop_path, f"processed_data_{timestamp}.xlsx")
            
            # ìµœì‹  pandas ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ExcelWriter ì‚¬ìš©
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                self.df.to_excel(writer, index=False)
            self.logger.info(f"ğŸ’¾ ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
            
            return output_path
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def get_data_summary(self) -> Dict:
        """ë°ì´í„° ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        try:
            if self.df is None:
                return {}
            
            summary = {
                'total_rows': len(self.df),
                'total_columns': len(self.df.columns),
                'columns': list(self.df.columns),
                'empty_cells': self.df.isnull().sum().sum(),
                'data_types': self.df.dtypes.to_dict()
            }
            
            # ì§€ì—­ë³„ ë¶„í¬
            if 'region' in self.df.columns:
                summary['region_distribution'] = self.df['region'].value_counts().to_dict()
            
            return summary
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ìš”ì•½ ì‹¤íŒ¨: {e}")
            return {} 