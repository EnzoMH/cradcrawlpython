#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤
"""

import time
import random
import logging
import re
from typing import Optional, List, Dict
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from .homepage_crawler import HomepageCrawler

class GoogleSearchEngine:
    """êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤"""
    
    def __init__(self, logger=None):
        """
        êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            logger: ë¡œê¹… ê°ì²´ (ê¸°ë³¸ê°’: None)
        """
        self.logger = logger or logging.getLogger(__name__)
        
        # HomepageCrawler ì´ˆê¸°í™”
        self.homepage_crawler = HomepageCrawler(logger)
        
        # êµ¬ê¸€ ê²€ìƒ‰ URL
        self.search_url = "https://www.google.com/search"
        
        # íŒ©ìŠ¤ë²ˆí˜¸ ì •ê·œì‹ íŒ¨í„´
        self.fax_patterns = [
            r'íŒ©ìŠ¤[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'fax[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'F[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'ì „ì†¡[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}).*íŒ©ìŠ¤',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}).*fax',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}).*ì „ì†¡',
        ]
        
        # ê²€ìƒ‰ ê²°ê³¼ ì„ íƒì
        self.result_selectors = [
            'div.g',
            'div[data-ved]',
            '.rc',
            '.tF2Cxc'
        ]
        
        # ë§í¬ ì„ íƒì
        self.link_selectors = [
            'h3 a',
            'a[href*="http"]',
            '.yuRUbf a'
        ]
    
    def search(self, query: str, driver, max_results: int = 5) -> List[Dict]:
        """
        êµ¬ê¸€ ê²€ìƒ‰ ì‹¤í–‰ (comp.py í˜¸í™˜ì„± ë©”ì„œë“œ)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
        """
        return self.search_google(driver, query, max_results)
    
    def search_google(self, driver, query: str, max_results: int = 5) -> List[Dict]:
        """
        êµ¬ê¸€ ê²€ìƒ‰ ì‹¤í–‰
        
        Args:
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
        """
        try:
            # ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™
            search_params = f"?q={query.replace(' ', '+')}"
            driver.get(self.search_url + search_params)
            
            # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            time.sleep(random.uniform(2, 4))
            
            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            results = self._parse_search_results(driver, max_results)
            
            self.logger.info(f"ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ì™„ë£Œ: '{query}' - {len(results)}ê°œ ê²°ê³¼")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {query} - {e}")
            return []
    
    def _parse_search_results(self, driver, max_results: int) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±"""
        results = []
        
        try:
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì†Œ ì°¾ê¸°
            result_elements = []
            for selector in self.result_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        result_elements = elements[:max_results]
                        break
                except:
                    continue
            
            if not result_elements:
                self.logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê° ê²°ê³¼ ì²˜ë¦¬
            for i, element in enumerate(result_elements):
                if i >= max_results:
                    break
                
                try:
                    result_data = self._extract_result_data(element)
                    if result_data:
                        results.append(result_data)
                        
                except Exception as e:
                    self.logger.debug(f"ê²°ê³¼ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_result_data(self, element) -> Optional[Dict]:
        """ê°œë³„ ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ì¶”ì¶œ"""
        try:
            result_data = {
                'title': '',
                'url': '',
                'snippet': '',
                'text_content': ''
            }
            
            # ì œëª©ê³¼ URL ì¶”ì¶œ
            link_element = None
            for selector in self.link_selectors:
                try:
                    link_element = element.find_element(By.CSS_SELECTOR, selector)
                    if link_element:
                        break
                except:
                    continue
            
            if link_element:
                result_data['title'] = link_element.text.strip()
                result_data['url'] = link_element.get_attribute('href')
            
            # ìŠ¤ë‹ˆí« ì¶”ì¶œ
            try:
                snippet_selectors = [
                    '.VwiC3b',
                    '.s3v9rd',
                    '.st',
                    'span[data-ved]'
                ]
                
                for selector in snippet_selectors:
                    try:
                        snippet_element = element.find_element(By.CSS_SELECTOR, selector)
                        if snippet_element:
                            result_data['snippet'] = snippet_element.text.strip()
                            break
                    except:
                        continue
                        
            except:
                pass
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ë‚´ìš©
            result_data['text_content'] = element.text.strip()
            
            # ìœ íš¨í•œ ê²°ê³¼ì¸ì§€ í™•ì¸
            if result_data['title'] and result_data['url']:
                return result_data
            
            return None
            
        except Exception as e:
            self.logger.debug(f"ê²°ê³¼ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def search_for_fax(self, driver, org_name: str, address: str = "", additional_info: str = "") -> List[str]:
        """
        íŒ©ìŠ¤ë²ˆí˜¸ ê²€ìƒ‰
        
        Args:
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            org_name: ê¸°ê´€ëª…
            address: ì£¼ì†Œ (ì„ íƒì‚¬í•­)
            additional_info: ì¶”ê°€ ì •ë³´ (ì„ íƒì‚¬í•­)
            
        Returns:
            List[str]: ë°œê²¬ëœ íŒ©ìŠ¤ë²ˆí˜¸ ëª©ë¡
        """
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            query_parts = [org_name, "íŒ©ìŠ¤", "fax"]
            if address:
                query_parts.append(address.split()[0])  # ì£¼ì†Œì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ë§Œ
            if additional_info:
                query_parts.append(additional_info)
            
            query = " ".join(query_parts)
            
            # êµ¬ê¸€ ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.search_google(driver, query, max_results=3)
            
            # íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ
            fax_numbers = []
            for result in search_results:
                found_fax = self._extract_fax_from_text(result['text_content'])
                fax_numbers.extend(found_fax)
                
                found_fax_snippet = self._extract_fax_from_text(result['snippet'])
                fax_numbers.extend(found_fax_snippet)
            
            # ì¤‘ë³µ ì œê±°
            unique_fax = list(set(fax_numbers))
            
            if unique_fax:
                self.logger.info(f"ğŸ“  íŒ©ìŠ¤ë²ˆí˜¸ ë°œê²¬: {org_name} - {unique_fax}")
            
            return unique_fax
            
        except Exception as e:
            self.logger.error(f"âŒ íŒ©ìŠ¤ë²ˆí˜¸ ê²€ìƒ‰ ì‹¤íŒ¨: {org_name} - {e}")
            return []
    
    def _extract_fax_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ"""
        try:
            if not text:
                return []
            
            fax_numbers = []
            
            for pattern in self.fax_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        fax_number = match[0] if match[0] else match[1] if len(match) > 1 else ""
                    else:
                        fax_number = match
                    
                    if fax_number:
                        # ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ê·œí™”
                        normalized = re.sub(r'[^\d]', '', fax_number)
                        if len(normalized) >= 8:  # ìµœì†Œ 8ìë¦¬
                            fax_numbers.append(fax_number)
            
            return fax_numbers
            
        except Exception as e:
            self.logger.error(f"âŒ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def search_for_phone(self, driver, org_name: str, address: str = "") -> List[str]:
        """
        ì „í™”ë²ˆí˜¸ ê²€ìƒ‰
        
        Args:
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            org_name: ê¸°ê´€ëª…
            address: ì£¼ì†Œ (ì„ íƒì‚¬í•­)
            
        Returns:
            List[str]: ë°œê²¬ëœ ì „í™”ë²ˆí˜¸ ëª©ë¡
        """
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            query_parts = [org_name, "ì „í™”ë²ˆí˜¸", "ì—°ë½ì²˜"]
            if address:
                query_parts.append(address.split()[0])
            
            query = " ".join(query_parts)
            
            # êµ¬ê¸€ ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.search_google(driver, query, max_results=3)
            
            # ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
            phone_numbers = []
            phone_pattern = r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})'
            
            for result in search_results:
                text_content = result['text_content'] + " " + result['snippet']
                matches = re.findall(phone_pattern, text_content)
                
                for match in matches:
                    normalized = re.sub(r'[^\d]', '', match)
                    if len(normalized) >= 8:
                        phone_numbers.append(match)
            
            # ì¤‘ë³µ ì œê±°
            unique_phones = list(set(phone_numbers))
            
            if unique_phones:
                self.logger.info(f"ğŸ“ ì „í™”ë²ˆí˜¸ ë°œê²¬: {org_name} - {unique_phones}")
            
            return unique_phones
            
        except Exception as e:
            self.logger.error(f"âŒ ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ ì‹¤íŒ¨: {org_name} - {e}")
            return []
    
    def search_for_homepage(self, driver, org_name: str, address: str = "") -> Optional[str]:
        """
        í™ˆí˜ì´ì§€ URL ê²€ìƒ‰
        
        Args:
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            org_name: ê¸°ê´€ëª…
            address: ì£¼ì†Œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Optional[str]: ë°œê²¬ëœ í™ˆí˜ì´ì§€ URL
        """
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            query_parts = [org_name, "í™ˆí˜ì´ì§€", "ì‚¬ì´íŠ¸"]
            if address:
                query_parts.append(address.split()[0])
            
            query = " ".join(query_parts)
            
            # êµ¬ê¸€ ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.search_google(driver, query, max_results=5)
            
            # ê³µì‹ í™ˆí˜ì´ì§€ë¡œ ë³´ì´ëŠ” URL ì°¾ê¸°
            for result in search_results:
                url = result['url']
                title = result['title'].lower()
                
                # ê³µì‹ ì‚¬ì´íŠ¸ë¡œ ë³´ì´ëŠ” í‚¤ì›Œë“œ ì²´í¬
                if any(keyword in title for keyword in ['ê³µì‹', 'í™ˆí˜ì´ì§€', org_name.lower()]):
                    # ì¼ë°˜ì ì¸ í™ˆí˜ì´ì§€ ë„ë©”ì¸ íŒ¨í„´ ì²´í¬
                    if any(domain in url for domain in ['.or.kr', '.go.kr', '.com', '.net', '.org']):
                        self.logger.info(f"ğŸŒ í™ˆí˜ì´ì§€ ë°œê²¬: {org_name} - {url}")
                        return url
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜ (ê³µì‹ ì‚¬ì´íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°)
            if search_results:
                url = search_results[0]['url']
                self.logger.info(f"ğŸŒ í™ˆí˜ì´ì§€ (ì¶”ì •): {org_name} - {url}")
                return url
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {org_name} - {e}")
            return None
    
    def search_for_institution_name(self, driver, org_name: str, address: str = "", additional_info: str = "") -> Optional[str]:
        """
        ê¸°ê´€ëª… ê²€ìƒ‰ (5ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ) - ë´‡ ìš°íšŒ ê°•í™”
        
        Args:
            driver: WebDriver ì¸ìŠ¤í„´ìŠ¤
            org_name: ê¸°ê´€ëª… ë˜ëŠ” ì „í™”ë²ˆí˜¸
            address: ì£¼ì†Œ (ì„ íƒì‚¬í•­)
            additional_info: ì¶”ê°€ ì •ë³´
            
        Returns:
            Optional[str]: ê²€ìƒ‰ëœ ê¸°ê´€ëª… ë˜ëŠ” None
        """
        if not driver:
            self.logger.error("âŒ WebDriverê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
            return None
        
        # ë´‡ ìš°íšŒë¥¼ ìœ„í•œ ëœë¤ ì§€ì—°
        import time
        import random
        initial_delay = random.uniform(1.0, 3.0)
        time.sleep(initial_delay)
        
        max_retries = 3
        bot_detection_retry = 0
        
        for retry in range(max_retries):
            try:
                self.logger.info(f"ğŸ” ê¸°ê´€ëª… ê²€ìƒ‰ ì‹œì‘ ({retry + 1}/{max_retries}): {org_name}")
                
                # 1ë‹¨ê³„: ê¸°ë³¸ êµ¬ê¸€ ê²€ìƒ‰
                result = self._search_basic_google(driver, org_name, address)
                if result:
                    self.logger.info(f"âœ… 1ë‹¨ê³„ ì„±ê³µ: {result}")
                    return result
                
                # 2ë‹¨ê³„: ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹œë„
                result = self._search_with_variations(driver, org_name, address)
                if result:
                    self.logger.info(f"âœ… 2ë‹¨ê³„ ì„±ê³µ: {result}")
                    return result
                
                # 3ë‹¨ê³„: AI ê¸°ë°˜ ê²€ìƒ‰ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
                result = self._search_with_ai_analysis(driver, org_name, address)
                if result:
                    self.logger.info(f"âœ… 3ë‹¨ê³„ ì„±ê³µ: {result}")
                    return result
                
                # 4ë‹¨ê³„: í™ˆí˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§
                result = self._search_homepage_direct(driver, org_name, address)
                if result:
                    self.logger.info(f"âœ… 4ë‹¨ê³„ ì„±ê³µ: {result}")
                    return result
                
                # 5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° í•„í„°ë§
                result = self._final_validation_search(driver, org_name)
                if result:
                    self.logger.info(f"âœ… 5ë‹¨ê³„ ì„±ê³µ: {result}")
                    return result
                
                # ì¬ì‹œë„ ì „ ë´‡ ê°ì§€ íšŒí”¼ ëŒ€ê¸°
                if retry < max_retries - 1:
                    retry_delay = random.uniform(3.0, 8.0) * (retry + 1)
                    self.logger.warning(f"â±ï¸ ì¬ì‹œë„ ì „ ëŒ€ê¸°: {retry_delay:.1f}ì´ˆ")
                    time.sleep(retry_delay)
            
            except Exception as e:
                error_msg = str(e).lower()
                
                # ë´‡ ê°ì§€ ì²´í¬
                if any(keyword in error_msg for keyword in ['bot', 'captcha', 'blocked', 'detected', 'too many requests']):
                    bot_detection_retry += 1
                    self.logger.warning(f"ğŸ¤– ë´‡ ê°ì§€ ë°œìƒ ({bot_detection_retry}íšŒ): {e}")
                    
                    # ë´‡ ê°ì§€ì‹œ ê¸´ ëŒ€ê¸°
                    bot_delay = random.uniform(15.0, 30.0) * bot_detection_retry
                    self.logger.warning(f"ğŸ›¡ï¸ ë´‡ ê°ì§€ ëŒ€ê¸°: {bot_delay:.1f}ì´ˆ")
                    time.sleep(bot_delay)
                    
                    # ë“œë¼ì´ë²„ ë³µêµ¬ ì‹œë„
                    if hasattr(driver, 'refresh'):
                        try:
                            driver.refresh()
                            time.sleep(random.uniform(2.0, 4.0))
                        except:
                            pass
                else:
                    self.logger.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜ ({retry + 1}/{max_retries}): {e}")
                    
                    if retry < max_retries - 1:
                        error_delay = random.uniform(2.0, 5.0)
                        time.sleep(error_delay)
        
        self.logger.warning(f"âŒ ëª¨ë“  ë‹¨ê³„ ì‹¤íŒ¨: {org_name}")
        return None
    
    def _search_basic_google(self, driver, org_name: str, address: str = "") -> Optional[str]:
        """1ë‹¨ê³„: ê¸°ë³¸ êµ¬ê¸€ ê²€ìƒ‰ (ë´‡ ìš°íšŒ ê°•í™”)"""
        try:
            import time
            import random
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.common.keys import Keys
            from bs4 import BeautifulSoup
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            if address:
                search_query = f"{address.split()[0]} {org_name} ì—°ë½ì²˜"
            else:
                search_query = f"{org_name} ê¸°ê´€ëª…"
            
            # êµ¬ê¸€ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™ (ë´‡ ìš°íšŒ)
            driver.get('https://www.google.com')
            time.sleep(random.uniform(1.5, 3.0))
            
            # ê²€ìƒ‰ì°½ ì°¾ê¸°
            search_box = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.NAME, 'q'))
            )
            
            # ì¸ê°„ì²˜ëŸ¼ ì²œì²œíˆ ì…ë ¥
            search_box.clear()
            for char in search_query:
                search_box.send_keys(char)
                time.sleep(random.uniform(0.05, 0.15))
            
            time.sleep(random.uniform(0.8, 1.5))
            search_box.send_keys(Keys.RETURN)
            
            # ê²°ê³¼ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.ID, 'search'))
            )
            
            time.sleep(random.uniform(2.0, 4.0))
            
            # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
            page_source = driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            text_content = soup.get_text()
            
            # ê¸°ê´€ëª… ì¶”ì¶œ ì‹œë„
            institution_name = self._extract_institution_name(text_content, org_name)
            
            if institution_name:
                return institution_name
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def _search_with_variations(self, driver, org_name: str, address: str = "") -> Optional[str]:
        """2ë‹¨ê³„: ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹œë„"""
        try:
            import time
            import random
            
            # ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ íŒ¨í„´
            query_variations = [
                f"{org_name} ì‹¤ì œê¸°ê´€ëª…",
                f"{org_name} ì •ì‹ëª…ì¹­",
                f"{org_name} ê³µì‹ëª…ì¹­",
                f"{org_name} site:*.go.kr",
                f"{org_name} site:*.or.kr"
            ]
            
            if address:
                location = address.split()[0]
                query_variations.extend([
                    f"{location} {org_name}",
                    f'"{org_name}" {location}'
                ])
            
            for query in query_variations:
                try:
                    result = self._perform_google_search(driver, query)
                    if result:
                        return result
                    
                    # ê²€ìƒ‰ ê°„ ì§€ì—°
                    time.sleep(random.uniform(2.0, 4.0))
                    
                except Exception as e:
                    self.logger.debug(f"ê²€ìƒ‰ ë³€í˜• ì‹¤íŒ¨: {query} - {e}")
                    continue
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ê²€ìƒ‰ ë³€í˜• ì‹¤íŒ¨: {e}")
            return None
    
    def _search_with_ai_analysis(self, driver, org_name: str, address: str = "") -> Optional[str]:
        """3ë‹¨ê³„: AI ê¸°ë°˜ ê²€ìƒ‰ ë¶„ì„ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)"""
        try:
            # ì´ ë¶€ë¶„ì€ ë‚˜ì¤‘ì— AI ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ êµ¬í˜„
            return None
            
        except Exception as e:
            self.logger.debug(f"AI ë¶„ì„ ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°: {e}")
            return None
    
    def _search_homepage_direct(self, driver, org_name: str, address: str = "") -> Optional[str]:
        """4ë‹¨ê³„: í™ˆí˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§"""
        try:
            # HomepageCrawler ì‚¬ìš©
            homepage_result = self.homepage_crawler.crawl_homepage_for_institution(
                driver, org_name, address
            )
            
            if homepage_result and homepage_result.get('institution_name'):
                return homepage_result['institution_name']
            
            return None
            
        except Exception as e:
            self.logger.debug(f"í™ˆí˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None
    
    def _final_validation_search(self, driver, org_name: str) -> Optional[str]:
        """5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° í•„í„°ë§"""
        try:
            # ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ë‹¨ìˆœí•œ ê²€ìƒ‰ ì‹œë„
            result = self._perform_simple_search(driver, org_name)
            
            if result:
                # ê²°ê³¼ ê²€ì¦
                if self._validate_institution_name(result, org_name):
                    return result
            
            return None
            
        except Exception as e:
            self.logger.debug(f"ìµœì¢… ê²€ì¦ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def _perform_google_search(self, driver, query: str) -> Optional[str]:
        """êµ¬ê¸€ ê²€ìƒ‰ ìˆ˜í–‰ (ê³µí†µ ë¡œì§)"""
        try:
            import time
            import random
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.common.keys import Keys
            from bs4 import BeautifulSoup
            
            # ìƒˆë¡œìš´ íƒ­ì—ì„œ ê²€ìƒ‰ (ë´‡ ê°ì§€ íšŒí”¼)
            driver.execute_script("window.open('');")
            driver.switch_to.window(driver.window_handles[-1])
            
            # êµ¬ê¸€ ê²€ìƒ‰
            driver.get('https://www.google.com')
            time.sleep(random.uniform(1.0, 2.5))
            
            search_box = WebDriverWait(driver, 8).until(
                EC.presence_of_element_located((By.NAME, 'q'))
            )
            
            search_box.clear()
            search_box.send_keys(query)
            time.sleep(random.uniform(0.5, 1.0))
            search_box.send_keys(Keys.RETURN)
            
            WebDriverWait(driver, 8).until(
                EC.presence_of_element_located((By.ID, 'search'))
            )
            
            time.sleep(random.uniform(1.5, 3.0))
            
            # ê²°ê³¼ ë¶„ì„
            page_source = driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            text_content = soup.get_text()
            
            # íƒ­ ë‹«ê¸°
            driver.close()
            driver.switch_to.window(driver.window_handles[0])
            
            return self._extract_institution_name(text_content, query)
            
        except Exception as e:
            # íƒ­ ì •ë¦¬
            try:
                if len(driver.window_handles) > 1:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
            except:
                pass
            
            self.logger.debug(f"êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {query} - {e}")
            return None
    
    def _perform_simple_search(self, driver, org_name: str) -> Optional[str]:
        """ë‹¨ìˆœ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            return self._perform_google_search(driver, f'"{org_name}"')
        except Exception as e:
            self.logger.debug(f"ë‹¨ìˆœ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_institution_name(self, text_content: str, org_name: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ì ì¸ ê¸°ê´€ëª… ì¶”ì¶œ ë¡œì§
            # ë” ì •êµí•œ ë¡œì§ì´ í•„ìš”í•˜ë©´ ë‚˜ì¤‘ì— ê°œì„ 
            
            # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
            if org_name in text_content:
                # org_name ì£¼ë³€ì˜ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ê´€ëª… ì°¾ê¸°
                lines = text_content.split('\n')
                for line in lines:
                    if org_name in line:
                        # ë¼ì¸ì—ì„œ ê¸°ê´€ëª…ì²˜ëŸ¼ ë³´ì´ëŠ” ë¶€ë¶„ ì¶”ì¶œ
                        words = line.split()
                        for word in words:
                            if len(word) > 2 and ('ì„¼í„°' in word or 'ê¸°ê´€' in word or 'ì²­' in word):
                                return word.strip()
            
            return None
            
        except Exception as e:
            self.logger.debug(f"ê¸°ê´€ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _validate_institution_name(self, name: str, original: str) -> bool:
        """ê¸°ê´€ëª… ê²€ì¦"""
        try:
            if not name or len(name) < 2:
                return False
            
            # ê¸ˆì§€ëœ íŒ¨í„´ ì²´í¬
            forbidden_patterns = ['ì˜¥ì…˜ì›ëª¨ë°”ì¼', 'ê´‘ê³ ', 'ë°°ë„ˆ', 'í´ë¦­', 'ë§í¬']
            for pattern in forbidden_patterns:
                if pattern in name:
                    return False
            
            return True
            
        except Exception as e:
            self.logger.debug(f"ê¸°ê´€ëª… ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _is_valid_institution_name(self, text: str, original_name: str) -> bool:
        """ìœ íš¨í•œ ê¸°ê´€ëª…ì¸ì§€ ê²€ì¦"""
        try:
            if not text or len(text.strip()) < 2:
                return False
            
            text = text.strip()
            
            # ê¸ˆì§€ëœ í‚¤ì›Œë“œ í™•ì¸
            forbidden_keywords = [
                "ì˜¥ì…˜ì›ëª¨ë°”ì¼", "ê´‘ê³ ", "ë°°ë„ˆ", "í´ë¦­", "ë°”ë¡œê°€ê¸°", 
                "ë„¤ì´ë²„", "êµ¬ê¸€", "ê²€ìƒ‰", "ëª¨ë°”ì¼", "ì•±", "ë‹¤ìš´ë¡œë“œ"
            ]
            
            for keyword in forbidden_keywords:
                if keyword in text:
                    return False
            
            # ê²€ìƒ‰ê²°ê³¼ íŒ¨í„´ í™•ì¸
            invalid_patterns = [
                r'ê²€ìƒ‰ê²°ê³¼.*ì„¼í„°',
                r'.*ëª¨ë°”ì¼.*ì„¼í„°',
                r'\d+.*ì„¼í„°.*\d+',  # ìˆ«ìê°€ í¬í•¨ëœ ì´ìƒí•œ íŒ¨í„´
            ]
            
            for pattern in invalid_patterns:
                if re.search(pattern, text):
                    return False
            
            # ìœ íš¨í•œ ê¸°ê´€ íŒ¨í„´ í™•ì¸
            valid_patterns = [
                r'.*ì£¼ë¯¼ì„¼í„°$',
                r'.*êµ¬ì²­$',
                r'.*ì‹œì²­$',
                r'.*ë™ì‚¬ë¬´ì†Œ$',
                r'.*ë©´ì‚¬ë¬´ì†Œ$',
                r'.*ìì‚¬ë¬´ì†Œ$',
                r'.*ë™ì£¼ë¯¼ì„¼í„°$'
            ]
            
            for pattern in valid_patterns:
                if re.search(pattern, text):
                    return True
            
            # ì›ë³¸ ê¸°ê´€ëª…ê³¼ì˜ ìœ ì‚¬ì„± ê²€ì‚¬
            if original_name in text or text in original_name:
                return True
            
            return False
            
        except Exception as e:
            self.logger.debug(f"ê¸°ê´€ëª… ê²€ì¦ ì˜¤ë¥˜: {e}")
            return False
    
    def _extract_institution_from_text(self, text: str, org_name: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê¸°ê´€ëª… ì¶”ì¶œ"""
        try:
            # ê°„ë‹¨í•œ ì¶”ì¶œ ë¡œì§ - ì¤„ë°”ê¿ˆì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìë¡œ ë¶„ë¦¬ëœ ì²« ë²ˆì§¸ ìœ íš¨í•œ ë¶€ë¶„
            parts = re.split(r'[\n\r\|Â·â€¢]', text)
            
            for part in parts:
                part = part.strip()
                if self._is_valid_institution_name(part, org_name):
                    return part
            
            return None
            
        except Exception as e:
            self.logger.debug(f"ê¸°ê´€ëª… ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def get_search_delay(self) -> float:
        """ê²€ìƒ‰ ê°„ ì§€ì—° ì‹œê°„ ë°˜í™˜"""
        return random.uniform(2.0, 4.0)


# ì „ì—­ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´)
def search_google_improved(driver, query: str, fax_patterns: List[str]):
    """ê°œì„ ëœ êµ¬ê¸€ ê²€ìƒ‰ (í˜¸í™˜ì„± í•¨ìˆ˜)"""
    engine = GoogleSearchEngine()
    return engine.search_google(driver, query)

def search_google_for_fax(driver, org_name: str, address: str = ""):
    """íŒ©ìŠ¤ë²ˆí˜¸ êµ¬ê¸€ ê²€ìƒ‰ (í˜¸í™˜ì„± í•¨ìˆ˜)"""
    engine = GoogleSearchEngine()
    return engine.search_for_fax(driver, org_name, address) 