#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë³‘ë ¬ í¬ë¡¤ë§ ì—”ì§„ - ProcessPoolExecutor ê¸°ë°˜ ì•ˆì •ì ì¸ ë³‘ë ¬ ì²˜ë¦¬
"""

import time
import logging
import multiprocessing
import random
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from typing import Dict, List, Optional, Callable, Any
from datetime import datetime
import pandas as pd
from utils.system.system_analyzer import SystemAnalyzer

# ===== ë…ë¦½ì ì¸ ì›Œì»¤ í•¨ìˆ˜ë“¤ =====

def create_worker_driver(worker_id: int):
    """
    ì›Œì»¤ìš© WebDriver ìƒì„± (í”„ë¡œì„¸ìŠ¤ ë¶„ë¦¬ ë°©ì‹)
    
    Args:
        worker_id: ì›Œì»¤ ID
        
    Returns:
        WebDriver ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
    """
    try:
        import undetected_chromedriver as uc
        import random
        import time
        
        # ì›Œì»¤ ê°„ ì‹œì°¨ ë‘ê¸° (íŒŒì¼ ì ‘ê·¼ ì¶©ëŒ ë°©ì§€)
        startup_delay = random.uniform(1.0, 3.0) * (worker_id + 1)
        time.sleep(startup_delay)
        
        chrome_options = uc.ChromeOptions()
        
        # ê¸°ë³¸ ì˜µì…˜
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1366,768')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--mute-audio')
        chrome_options.add_argument('--no-first-run')
        chrome_options.add_argument('--disable-infobars')
        chrome_options.add_argument('--disable-notifications')
        
        # ğŸ›¡ï¸ ë¦¬ì†ŒìŠ¤ ì ˆì•½ ì˜µì…˜
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-features=TranslateUI')
        chrome_options.add_argument('--disable-default-apps')
        chrome_options.add_argument('--disable-sync')
        
        # ë©”ëª¨ë¦¬ ì œí•œ
        chrome_options.add_argument('--memory-pressure-off')
        chrome_options.add_argument('--max_old_space_size=256')
        chrome_options.add_argument('--aggressive-cache-discard')
        chrome_options.add_argument('--max-unused-resource-memory-usage-percentage=5')
        
        # ì•ˆì „í•œ í¬íŠ¸ ì„¤ì • (ì¶©ëŒ ë°©ì§€)
        debug_port = 9222 + (worker_id * 10)
        chrome_options.add_argument(f'--remote-debugging-port={debug_port}')
        
        # User-Agent ëœë¤í™”
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'
        ]
        chrome_options.add_argument(f'--user-agent={random.choice(user_agents)}')
        
        # ë“œë¼ì´ë²„ ìƒì„±
        driver = uc.Chrome(options=chrome_options, version_main=None)
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        driver.implicitly_wait(10)
        driver.set_page_load_timeout(30)
        
        # ì›¹ë“œë¼ì´ë²„ ê°ì§€ ë°©ì§€
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        print(f"ğŸ”§ ì›Œì»¤ {worker_id}: WebDriver ìƒì„± ì™„ë£Œ (í¬íŠ¸: {debug_port})")
        return driver
        
    except Exception as e:
        print(f"âŒ ì›Œì»¤ {worker_id} WebDriver ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def process_institution_worker(institution_data: Dict, worker_id: int) -> Dict:
    """
    ë…ë¦½ì ì¸ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œ ê¸°ê´€ ì²˜ë¦¬
    
    Args:
        institution_data: ê¸°ê´€ ì •ë³´
        worker_id: ì›Œì»¤ ID
        
    Returns:
        Dict: ì²˜ë¦¬ ê²°ê³¼
    """
    import os
    import sys
    import logging
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format=f'%(asctime)s - Worker{worker_id} - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(f'worker_{worker_id}')
    
    driver = None
    try:
        institution_name = institution_data.get('institution_name', '')
        region = institution_data.get('region', '')
        address = institution_data.get('address', '')
        
        logger.info(f"ğŸ¢ [{worker_id}] {institution_name} ì²˜ë¦¬ ì‹œì‘")
        
        # WebDriver ì´ˆê¸°í™”
        driver = create_worker_driver(worker_id)
        if not driver:
            logger.error(f"âŒ [{worker_id}] WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨")
            return institution_data
        
        # ì—¬ê¸°ì„œ ì‹¤ì œ í¬ë¡¤ë§ ë¡œì§ êµ¬í˜„
        # 1. ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
        logger.info(f"ğŸ“ [{worker_id}] {institution_name} ì „í™”ë²ˆí˜¸ ì¶”ì¶œ")
        phone = search_google_for_phone(driver, institution_name, region, address)
        
        # 2. íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ
        logger.info(f"ğŸ“  [{worker_id}] {institution_name} íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ")
        fax = search_google_for_fax(driver, institution_name, region, address)
        
        # 3. í™ˆí˜ì´ì§€ ì¶”ì¶œ
        logger.info(f"ğŸŒ [{worker_id}] {institution_name} í™ˆí˜ì´ì§€ ì¶”ì¶œ")
        homepage = search_google_for_homepage(driver, institution_name, region, address)
        
        # ê²°ê³¼ êµ¬ì„±
        result = institution_data.copy()
        result.update({
            'phone': phone or '',
            'fax': fax or '',
            'homepage': homepage or '',
            'processing_status': 'completed',
            'worker_id': worker_id
        })
        
        logger.info(f"âœ… [{worker_id}] {institution_name} ì²˜ë¦¬ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ [{worker_id}] {institution_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        result = institution_data.copy()
        result.update({
            'processing_status': 'failed',
            'error_message': str(e),
            'worker_id': worker_id
        })
        return result
        
    finally:
        if driver:
            try:
                driver.quit()
                logger.info(f"ğŸ§¹ [{worker_id}] WebDriver ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ [{worker_id}] WebDriver ì •ë¦¬ ì‹¤íŒ¨: {e}")

def search_google_for_phone(driver, institution_name: str, region: str, address: str) -> str:
    """êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ"""
    try:
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.keys import Keys
        from bs4 import BeautifulSoup
        import re
        import time
        import random
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = f"{region} {institution_name} ì „í™”ë²ˆí˜¸"
        
        # êµ¬ê¸€ ê²€ìƒ‰
        driver.get('https://www.google.com')
        time.sleep(random.uniform(1.0, 2.0))
        
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.NAME, 'q'))
        )
        
        search_box.clear()
        search_box.send_keys(search_query)
        search_box.send_keys(Keys.RETURN)
        
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, 'search'))
        )
        time.sleep(random.uniform(1.0, 2.0))
        
        # ì „í™”ë²ˆí˜¸ íŒ¨í„´ ì¶”ì¶œ
        page_source = driver.page_source
        phone_patterns = [
            r'ì „í™”[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'tel[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'T[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'ì—°ë½ì²˜[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
        ]
        
        for pattern in phone_patterns:
            matches = re.findall(pattern, page_source, re.IGNORECASE)
            for match in matches:
                normalized = normalize_phone_number(match)
                if is_valid_phone_format(normalized):
                    return normalized
        
        return None
        
    except Exception as e:
        print(f"âŒ ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def search_google_for_fax(driver, institution_name: str, region: str, address: str) -> str:
    """êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ"""
    try:
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.keys import Keys
        from bs4 import BeautifulSoup
        import re
        import time
        import random
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = f"{region} {institution_name} íŒ©ìŠ¤ë²ˆí˜¸"
        
        # êµ¬ê¸€ ê²€ìƒ‰
        driver.get('https://www.google.com')
        time.sleep(random.uniform(1.0, 2.0))
        
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.NAME, 'q'))
        )
        
        search_box.clear()
        search_box.send_keys(search_query)
        search_box.send_keys(Keys.RETURN)
        
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, 'search'))
        )
        time.sleep(random.uniform(1.0, 2.0))
        
        # íŒ©ìŠ¤ë²ˆí˜¸ íŒ¨í„´ ì¶”ì¶œ
        page_source = driver.page_source
        fax_patterns = [
            r'íŒ©ìŠ¤[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'fax[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'F[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'ì „ì†¡[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}).*íŒ©ìŠ¤',
            r'(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}).*fax',
        ]
        
        for pattern in fax_patterns:
            matches = re.findall(pattern, page_source, re.IGNORECASE)
            for match in matches:
                normalized = normalize_phone_number(match)
                if is_valid_phone_format(normalized):
                    return normalized
        
        return None
        
    except Exception as e:
        print(f"âŒ íŒ©ìŠ¤ë²ˆí˜¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def search_google_for_homepage(driver, institution_name: str, region: str, address: str) -> str:
    """êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ í™ˆí˜ì´ì§€ ì¶”ì¶œ"""
    try:
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.keys import Keys
        from bs4 import BeautifulSoup
        import re
        import time
        import random
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = f"{region} {institution_name} í™ˆí˜ì´ì§€"
        
        # êµ¬ê¸€ ê²€ìƒ‰
        driver.get('https://www.google.com')
        time.sleep(random.uniform(1.0, 2.0))
        
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.NAME, 'q'))
        )
        
        search_box.clear()
        search_box.send_keys(search_query)
        search_box.send_keys(Keys.RETURN)
        
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, 'search'))
        )
        time.sleep(random.uniform(1.0, 2.0))
        
        # ë§í¬ ì¶”ì¶œ
        links = driver.find_elements(By.CSS_SELECTOR, 'a[href]')
        for link in links:
            href = link.get_attribute('href')
            if href and is_valid_homepage_url(href):
                return href
        
        return None
        
    except Exception as e:
        print(f"âŒ í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def normalize_phone_number(phone: str) -> str:
    """ì „í™”ë²ˆí˜¸ ì •ê·œí™”"""
    import re
    numbers = re.findall(r'\d+', phone)
    if not numbers:
        return phone
    
    if len(numbers) >= 3:
        return f"{numbers[0]}-{numbers[1]}-{numbers[2]}"
    elif len(numbers) == 2:
        return f"{numbers[0]}-{numbers[1]}"
    else:
        return numbers[0]

def is_valid_phone_format(phone: str) -> bool:
    """ì „í™”ë²ˆí˜¸ í˜•ì‹ ìœ íš¨ì„± ê²€ì‚¬"""
    import re
    try:
        if not phone:
            return False
        
        digits = re.sub(r'[^\d]', '', phone)
        if len(digits) < 8 or len(digits) > 11:
            return False
        
        valid_patterns = [
            r'^02\d{7,8}$',
            r'^0[3-6]\d{7,8}$',
            r'^070\d{7,8}$',
            r'^1[5-9]\d{6,7}$',
            r'^080\d{7,8}$',
        ]
        
        for pattern in valid_patterns:
            if re.match(pattern, digits):
                return True
        
        return False
        
    except Exception:
        return False

def is_valid_homepage_url(url: str) -> bool:
    """í™ˆí˜ì´ì§€ URL ìœ íš¨ì„± ê²€ì‚¬"""
    import re
    try:
        if not url:
            return False
        
        # ê¸°ë³¸ URL íŒ¨í„´ ê²€ì‚¬
        url_pattern = r'^https?://[^\s/$.?#].[^\s]*$'
        if not re.match(url_pattern, url):
            return False
        
        # ì œì™¸í•  ë„ë©”ì¸
        exclude_domains = [
            'google.com', 'youtube.com', 'facebook.com', 'instagram.com',
            'naver.com', 'daum.net', 'tistory.com', 'blogger.com'
        ]
        
        for domain in exclude_domains:
            if domain in url:
                return False
        
        return True
        
    except Exception:
        return False

class CrawlingEngine:
    """ë³‘ë ¬ í¬ë¡¤ë§ ì—”ì§„ - ProcessPoolExecutor ê¸°ë°˜"""
    
    def __init__(self, logger=None):
        """
        í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            logger: ë¡œê¹… ê°ì²´ (ê¸°ë³¸ê°’: None)
        """
        self.logger = logger or logging.getLogger(__name__)
        self.system_analyzer = SystemAnalyzer(self.logger)
        self.current_workers = 0
        self.max_workers = self.system_analyzer.get_optimal_workers()
        self.executor = None
        
        # í¬ë¡¤ë§ í†µê³„
        self.crawling_stats = {
            'total_institutions': 0,
            'processed_institutions': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'verified_contacts': 0,
            'start_time': None,
            'end_time': None
        }
        
        self.logger.info("ğŸš€ í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (ProcessPoolExecutor ê¸°ë°˜)")
        self.logger.info(f"âš™ï¸  ìµœì  ì›Œì»¤ ìˆ˜: {self.max_workers}ê°œ")
    
    def initialize_workers(self, worker_count: int = None) -> bool:
        """
        ì›Œì»¤ í’€ ì´ˆê¸°í™”
        
        Args:
            worker_count: ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: None - ìë™ ì„¤ì •)
            
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            if worker_count is None:
                worker_count = self.max_workers
            
            self.current_workers = min(worker_count, self.max_workers)
            
            # ProcessPoolExecutor ì‚¬ìš© (í”„ë¡œì„¸ìŠ¤ ë¶„ë¦¬)
            self.executor = ProcessPoolExecutor(max_workers=self.current_workers)
            
            self.logger.info(f"ğŸ‘¥ ì›Œì»¤ í’€ ì´ˆê¸°í™” ì™„ë£Œ: {self.current_workers}ê°œ í”„ë¡œì„¸ìŠ¤")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œì»¤ í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def process_institution_batch(self, institutions: List[Dict]) -> List[Dict]:
        """
        ê¸°ê´€ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            institutions: ê¸°ê´€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            self.logger.info(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(institutions)}ê°œ ê¸°ê´€")
            self.crawling_stats['total_institutions'] = len(institutions)
            self.crawling_stats['start_time'] = datetime.now()
            
            if not self.executor:
                if not self.initialize_workers():
                    return []
            
            # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            self.system_analyzer.start_monitoring()
            
            results = []
            futures = []
            
            # ì‘ì—… ì œì¶œ
            for i, institution in enumerate(institutions):
                future = self.executor.submit(process_institution_worker, institution, i)
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                    if result:
                        results.append(result)
                        if result.get('processing_status') == 'completed':
                            self.crawling_stats['successful_extractions'] += 1
                        else:
                            self.crawling_stats['failed_extractions'] += 1
                    
                    self.crawling_stats['processed_institutions'] += 1
                    
                    # ì§„í–‰ë¥  ë¡œê·¸
                    if self.crawling_stats['processed_institutions'] % 10 == 0:
                        self._log_progress()
                    
                except Exception as e:
                    self.logger.error(f"âŒ ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    self.crawling_stats['failed_extractions'] += 1
                    continue
            
            self.crawling_stats['end_time'] = datetime.now()
            self.system_analyzer.stop_monitoring()
            
            self.logger.info(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            self._log_final_stats()
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.system_analyzer.stop_monitoring()
            return []

    def process_region_data(self, region_data: pd.DataFrame, 
                           region_name: str) -> List[Dict]:
        """
        ì§€ì—­ë³„ ë°ì´í„° ì²˜ë¦¬
        
        Args:
            region_data: ì§€ì—­ ë°ì´í„°
            region_name: ì§€ì—­ëª…
            
        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            self.logger.info(f"ğŸ—ºï¸  {region_name} ì§€ì—­ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {len(region_data)}ê°œ")
            
            # ë°ì´í„°í”„ë ˆì„ì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            institutions = region_data.to_dict('records')
            
            # ë°°ì¹˜ ì²˜ë¦¬
            results = self.process_institution_batch(institutions)
            
            self.logger.info(f"âœ… {region_name} ì§€ì—­ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ {region_name} ì§€ì—­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def process_chunked_data(self, data_chunks: List[pd.DataFrame], 
                            region_name: str) -> List[Dict]:
        """
        ì²­í¬ ë‹¨ìœ„ ë°ì´í„° ì²˜ë¦¬
        
        Args:
            data_chunks: ë°ì´í„° ì²­í¬ ë¦¬ìŠ¤íŠ¸
            region_name: ì§€ì—­ëª…
            
        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            self.logger.info(f"ğŸ“¦ {region_name} ì²­í¬ ì²˜ë¦¬ ì‹œì‘: {len(data_chunks)}ê°œ ì²­í¬")
            
            all_results = []
            for i, chunk in enumerate(data_chunks):
                self.logger.info(f"ğŸ”„ ì²­í¬ {i+1}/{len(data_chunks)} ì²˜ë¦¬ ì¤‘...")
                
                # ì²­í¬ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                institutions = chunk.to_dict('records')
                
                # ë°°ì¹˜ ì²˜ë¦¬
                chunk_results = self.process_institution_batch(institutions)
                all_results.extend(chunk_results)
                
                # ì²­í¬ ê°„ íœ´ì‹
                if i < len(data_chunks) - 1:
                    rest_time = random.uniform(2.0, 5.0)
                    self.logger.info(f"â³ ì²­í¬ ê°„ íœ´ì‹: {rest_time:.1f}ì´ˆ")
                    time.sleep(rest_time)
            
            self.logger.info(f"âœ… {region_name} ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼")
            return all_results
            
        except Exception as e:
            self.logger.error(f"âŒ {region_name} ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def _log_progress(self):
        """ì§„í–‰ë¥  ë¡œê¹…"""
        try:
            total = self.crawling_stats['total_institutions']
            processed = self.crawling_stats['processed_institutions']
            success = self.crawling_stats['successful_extractions']
            failed = self.crawling_stats['failed_extractions']
            
            if total > 0:
                progress = (processed / total) * 100
                success_rate = (success / processed) * 100 if processed > 0 else 0
                
                self.logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {processed}/{total} ({progress:.1f}%) | "
                               f"ì„±ê³µë¥ : {success_rate:.1f}% | ì‹¤íŒ¨: {failed}ê°œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì§„í–‰ë¥  ë¡œê¹… ì‹¤íŒ¨: {e}")

    def _log_final_stats(self):
        """ìµœì¢… í†µê³„ ë¡œê¹…"""
        try:
            stats = self.crawling_stats
            
            if stats['start_time'] and stats['end_time']:
                duration = stats['end_time'] - stats['start_time']
                duration_str = str(duration).split('.')[0]  # ì´ˆ ë‹¨ìœ„ ì œê±°
                
                self.logger.info("ğŸ¯ ìµœì¢… í¬ë¡¤ë§ í†µê³„:")
                self.logger.info(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {duration_str}")
                self.logger.info(f"  - ì „ì²´ ê¸°ê´€ ìˆ˜: {stats['total_institutions']}")
                self.logger.info(f"  - ì²˜ë¦¬ ì™„ë£Œ: {stats['processed_institutions']}")
                self.logger.info(f"  - ì„±ê³µ ì¶”ì¶œ: {stats['successful_extractions']}")
                self.logger.info(f"  - ì‹¤íŒ¨ ì¶”ì¶œ: {stats['failed_extractions']}")
                self.logger.info(f"  - ê²€ì¦ ì™„ë£Œ: {stats['verified_contacts']}")
                
                if stats['processed_institutions'] > 0:
                    success_rate = (stats['successful_extractions'] / stats['processed_institutions']) * 100
                    self.logger.info(f"  - ì„±ê³µë¥ : {success_rate:.1f}%")
                    
                    avg_time = duration.total_seconds() / stats['processed_institutions']
                    self.logger.info(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.1f}ì´ˆ/ê¸°ê´€")
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… í†µê³„ ë¡œê¹… ì‹¤íŒ¨: {e}")

    def save_results(self, results: List[Dict], filename: str = None) -> str:
        """
        ê²°ê³¼ ì €ì¥
        
        Args:
            results: ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            filename: ì €ì¥í•  íŒŒì¼ëª… (ê¸°ë³¸ê°’: None - ìë™ ìƒì„±)
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"crawling_results_{timestamp}.xlsx"
            
            # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            df = pd.DataFrame(results)
            
            # Excel íŒŒì¼ë¡œ ì €ì¥ (encoding íŒŒë¼ë¯¸í„° ì œê±°)
            df.to_excel(filename, index=False)
            
            self.logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            self.logger.info(f"ğŸ“Š ì €ì¥ëœ ë°ì´í„°: {len(results)}ê°œ ê¸°ê´€")
            
            return filename
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def get_crawling_stats(self) -> Dict:
        """í¬ë¡¤ë§ í†µê³„ ë°˜í™˜"""
        return self.crawling_stats.copy()

    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.crawling_stats = {
            'total_institutions': 0,
            'processed_institutions': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'verified_contacts': 0,
            'start_time': None,
            'end_time': None
        }
        self.logger.info("ğŸ“Š í¬ë¡¤ë§ í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.executor:
                self.executor.shutdown(wait=True)
                self.executor = None
                self.logger.info("ğŸ§¹ í¬ë¡¤ë§ ì—”ì§„ ì •ë¦¬ ì™„ë£Œ")
                
            self.system_analyzer.stop_monitoring()
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ë¡¤ë§ ì—”ì§„ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        self.cleanup() 