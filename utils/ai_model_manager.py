#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤ - ë‹¤ì¤‘ Gemini API í‚¤ ì§€ì›
"""

import os
import logging
import google.generativeai as genai
from typing import Dict, List, Optional

# AI ëª¨ë¸ ì„¤ì •
AI_MODEL_CONFIG = {
    "temperature": 0.1,
    "top_p": 0.8,
    "top_k": 40,
    "max_output_tokens": 2048,
}

class AIModelManager:
    """AI ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤ - 4ê°œì˜ Gemini API í‚¤ ì§€ì›"""
    
    def __init__(self, logger=None):
        """
        AI ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            logger: ë¡œê¹… ê°ì²´ (ê¸°ë³¸ê°’: None)
        """
        self.logger = logger or logging.getLogger(__name__)
        self.gemini_models = []
        self.gemini_config = AI_MODEL_CONFIG
        self.current_model_index = 0
        self.setup_models()
    
    def setup_models(self):
        """4ê°œì˜ AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # API í‚¤ë“¤ ê°€ì ¸ì˜¤ê¸°
            api_keys = {
                'GEMINI_1': os.getenv('GEMINI_API_KEY_1'),
                'GEMINI_2': os.getenv('GEMINI_API_KEY_2'),
                'GEMINI_3': os.getenv('GEMINI_API_KEY_3'),
                'GEMINI_4': os.getenv('GEMINI_API_KEY_4')
            }
            
            # ìµœì†Œ í•˜ë‚˜ì˜ API í‚¤ëŠ” ìˆì–´ì•¼ í•¨
            valid_keys = {k: v for k, v in api_keys.items() if v}
            if not valid_keys:
                raise ValueError("GEMINI_API_KEY_1, GEMINI_API_KEY_2, GEMINI_API_KEY_3, ë˜ëŠ” GEMINI_API_KEY_4 í™˜ê²½ ë³€ìˆ˜ ì¤‘ ìµœì†Œ í•˜ë‚˜ëŠ” ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
            # ê° API í‚¤ì— ëŒ€í•´ ëª¨ë¸ ì´ˆê¸°í™”
            for model_name, api_key in valid_keys.items():
                try:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel(
                        "gemini-2.0-flash-lite-001",
                        generation_config=self.gemini_config
                    )
                    
                    self.gemini_models.append({
                        'model': model,
                        'api_key': api_key[:10] + "...",
                        'name': model_name,
                        'failures': 0
                    })
                    
                    self.logger.info(f"ğŸ¤– {model_name} ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {model_name} ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    continue
            
            if not self.gemini_models:
                raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            self.logger.info(f"ğŸ‰ ì´ {len(self.gemini_models)}ê°œì˜ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def get_next_model(self) -> Optional[Dict]:
        """ë‹¤ìŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„ íƒ (ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹)"""
        if not self.gemini_models:
            return None
        
        # ì‹¤íŒ¨ íšŸìˆ˜ê°€ ì ì€ ëª¨ë¸ ìš°ì„  ì„ íƒ
        available_models = [m for m in self.gemini_models if m['failures'] < 3]
        if not available_models:
            # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì‹¤íŒ¨ íšŸìˆ˜ ë¦¬ì…‹
            for model in self.gemini_models:
                model['failures'] = 0
            available_models = self.gemini_models
        
        # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì„ íƒ
        model = available_models[self.current_model_index % len(available_models)]
        self.current_model_index = (self.current_model_index + 1) % len(available_models)
        
        return model
    
    def extract_with_gemini(self, text_content: str, prompt_template: str) -> str:
        """
        Gemini APIë¥¼ í†µí•œ ì •ë³´ ì¶”ì¶œ (ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›)
        
        Args:
            text_content: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë‚´ìš©
            prompt_template: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ({text_content} í”Œë ˆì´ìŠ¤í™€ë” í¬í•¨)
            
        Returns:
            str: AI ì‘ë‹µ ê²°ê³¼
        """
        if not self.gemini_models:
            return "ì˜¤ë¥˜: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë“  ëª¨ë¸ì„ ì‹œë„í•´ë³¼ ìˆ˜ ìˆë„ë¡ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì„¤ì •
        max_attempts = len(self.gemini_models)
        
        for attempt in range(max_attempts):
            current_model = self.get_next_model()
            if not current_model:
                continue
            
            try:
                # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (Gemini API ì œí•œ)
                max_length = 32000
                if len(text_content) > max_length:
                    front_portion = int(max_length * 0.67)
                    back_portion = max_length - front_portion
                    text_content = text_content[:front_portion] + "\n... (ì¤‘ëµ) ...\n" + text_content[-back_portion:]
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = prompt_template.format(text_content=text_content)
                
                # í˜„ì¬ ëª¨ë¸ë¡œ API í˜¸ì¶œ
                response = current_model['model'].generate_content(prompt)
                result_text = response.text
                
                # ì„±ê³µ ì‹œ ë¡œê·¸ ì¶œë ¥
                self.logger.info(f"âœ… {current_model['name']} API ì„±ê³µ - ì‘ë‹µ (ì¼ë¶€): {result_text[:200]}...")
                
                return result_text
                
            except Exception as e:
                # ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„
                current_model['failures'] += 1
                self.logger.warning(f"âš ï¸ {current_model['name']} API ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_attempts}): {str(e)}")
                
                if attempt < max_attempts - 1:
                    self.logger.info(f"ğŸ”„ ë‹¤ìŒ ëª¨ë¸ë¡œ ì¬ì‹œë„ ì¤‘...")
                    continue
                else:
                    self.logger.error(f"âŒ ëª¨ë“  Gemini ëª¨ë¸ ì‹¤íŒ¨")
                    return f"ì˜¤ë¥˜: ëª¨ë“  API í˜¸ì¶œ ì‹¤íŒ¨ - ë§ˆì§€ë§‰ ì˜¤ë¥˜: {str(e)}"
        
        return "ì˜¤ë¥˜: ëª¨ë“  ëª¨ë¸ ì‹œë„ ì‹¤íŒ¨"
    
    def get_model_status(self) -> str:
        """ëª¨ë¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        if not self.gemini_models:
            return "âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ"
        
        status_info = []
        for model in self.gemini_models:
            status = "âœ… ì •ìƒ" if model['failures'] < 3 else "âŒ ì‹¤íŒ¨"
            status_info.append(f"{model['name']}: {status} (ì‹¤íŒ¨: {model['failures']}íšŒ)")
        
        return " | ".join(status_info)
    
    def reset_failures(self):
        """ëª¨ë“  ëª¨ë¸ì˜ ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”"""
        for model in self.gemini_models:
            model['failures'] = 0
        self.logger.info("ğŸ”„ ëª¨ë“  ëª¨ë¸ì˜ ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_available_models_count(self) -> int:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆ˜ ë°˜í™˜"""
        return len([m for m in self.gemini_models if m['failures'] < 3])
    
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸"""
        return self.get_available_models_count() > 0 